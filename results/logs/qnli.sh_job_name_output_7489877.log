######################################################################
full model fine-tuning
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:01,  1.82it/s]100%|██████████| 3/3 [00:00<00:00,  4.87it/s]
Map:   0%|          | 0/104743 [00:00<?, ? examples/s]Map:   0%|          | 125/104743 [00:00<01:24, 1232.46 examples/s]Map:   0%|          | 316/104743 [00:00<01:04, 1622.72 examples/s]Map:   0%|          | 511/104743 [00:00<00:58, 1767.00 examples/s]Map:   1%|          | 702/104743 [00:00<00:57, 1821.46 examples/s]Map:   1%|          | 909/104743 [00:00<00:54, 1907.14 examples/s]Map:   1%|          | 1133/104743 [00:00<01:30, 1141.65 examples/s]Map:   1%|▏         | 1394/104743 [00:00<01:11, 1455.53 examples/s]Map:   2%|▏         | 1653/104743 [00:01<00:59, 1719.84 examples/s]Map:   2%|▏         | 1915/104743 [00:01<00:52, 1944.53 examples/s]Map:   2%|▏         | 2264/104743 [00:01<01:06, 1549.05 examples/s]Map:   2%|▏         | 2526/104743 [00:01<00:58, 1760.09 examples/s]Map:   3%|▎         | 2785/104743 [00:01<00:52, 1941.81 examples/s]Map:   3%|▎         | 3131/104743 [00:01<01:04, 1581.42 examples/s]Map:   3%|▎         | 3396/104743 [00:02<00:56, 1783.64 examples/s]Map:   3%|▎         | 3659/104743 [00:02<00:51, 1961.78 examples/s]Map:   4%|▎         | 3926/104743 [00:02<00:47, 2124.54 examples/s]Map:   4%|▍         | 4267/104743 [00:02<00:59, 1688.61 examples/s]Map:   4%|▍         | 4527/104743 [00:02<00:53, 1867.68 examples/s]Map:   5%|▍         | 4790/104743 [00:02<00:49, 2033.48 examples/s]Map:   5%|▍         | 5133/104743 [00:02<01:00, 1635.46 examples/s]Map:   5%|▌         | 5394/104743 [00:03<00:54, 1820.97 examples/s]Map:   5%|▌         | 5655/104743 [00:03<00:49, 1989.53 examples/s]Map:   6%|▌         | 5914/104743 [00:03<00:46, 2128.34 examples/s]Map:   6%|▌         | 6263/104743 [00:03<01:08, 1445.41 examples/s]Map:   6%|▌         | 6527/104743 [00:03<00:59, 1651.06 examples/s]Map:   6%|▋         | 6790/104743 [00:03<00:53, 1843.18 examples/s]Map:   7%|▋         | 7133/104743 [00:04<01:02, 1561.57 examples/s]Map:   7%|▋         | 7335/104743 [00:04<00:59, 1643.84 examples/s]Map:   7%|▋         | 7560/104743 [00:04<00:55, 1762.20 examples/s]Map:   7%|▋         | 7820/104743 [00:04<00:49, 1951.34 examples/s]Map:   8%|▊         | 8133/104743 [00:04<01:01, 1566.40 examples/s]Map:   8%|▊         | 8394/104743 [00:04<00:54, 1769.60 examples/s]Map:   8%|▊         | 8655/104743 [00:04<00:49, 1951.94 examples/s]Map:   9%|▊         | 8917/104743 [00:05<00:45, 2110.92 examples/s]Map:   9%|▉         | 9261/104743 [00:05<00:57, 1655.00 examples/s]Map:   9%|▉         | 9525/104743 [00:05<00:51, 1847.43 examples/s]Map:   9%|▉         | 9786/104743 [00:05<00:47, 2012.15 examples/s]Map:  10%|▉         | 10134/104743 [00:05<00:57, 1634.74 examples/s]Map:  10%|▉         | 10395/104743 [00:05<00:51, 1819.94 examples/s]Map:  10%|█         | 10649/104743 [00:06<00:47, 1971.55 examples/s]Map:  10%|█         | 10910/104743 [00:06<00:44, 2118.82 examples/s]Map:  11%|█         | 11263/104743 [00:06<00:55, 1693.13 examples/s]Map:  11%|█         | 11526/104743 [00:06<00:49, 1874.43 examples/s]Map:  11%|█▏        | 11788/104743 [00:06<00:45, 2036.75 examples/s]Map:  12%|█▏        | 12133/104743 [00:06<00:57, 1621.44 examples/s]Map:  12%|█▏        | 12396/104743 [00:06<00:51, 1810.51 examples/s]Map:  12%|█▏        | 12657/104743 [00:07<00:46, 1979.53 examples/s]Map:  12%|█▏        | 12919/104743 [00:07<00:43, 2125.81 examples/s]Map:  13%|█▎        | 13264/104743 [00:07<00:54, 1683.16 examples/s]Map:  13%|█▎        | 13526/104743 [00:07<00:48, 1866.39 examples/s]Map:  13%|█▎        | 13780/104743 [00:07<00:45, 2011.67 examples/s]Map:  13%|█▎        | 14132/104743 [00:07<00:55, 1641.24 examples/s]Map:  14%|█▎        | 14395/104743 [00:08<00:49, 1829.30 examples/s]Map:  14%|█▍        | 14661/104743 [00:08<00:44, 2005.43 examples/s]Map:  14%|█▍        | 14921/104743 [00:08<00:41, 2143.91 examples/s]Map:  15%|█▍        | 15267/104743 [00:08<00:53, 1665.95 examples/s]Map:  15%|█▍        | 15527/104743 [00:08<00:48, 1846.18 examples/s]Map:  15%|█▌        | 15789/104743 [00:08<00:44, 2011.84 examples/s]Map:  15%|█▌        | 16121/104743 [00:09<00:54, 1624.21 examples/s]Map:  16%|█▌        | 16375/104743 [00:09<00:49, 1798.40 examples/s]Map:  16%|█▌        | 16624/104743 [00:09<00:45, 1946.28 examples/s]Map:  16%|█▌        | 16881/104743 [00:09<00:42, 2091.07 examples/s]Map:  16%|█▋        | 17133/104743 [00:09<00:55, 1587.64 examples/s]Map:  17%|█▋        | 17396/104743 [00:09<00:48, 1800.74 examples/s]Map:  17%|█▋        | 17656/104743 [00:09<00:44, 1979.11 examples/s]Map:  17%|█▋        | 17919/104743 [00:09<00:40, 2135.22 examples/s]Map:  17%|█▋        | 18264/104743 [00:10<00:52, 1660.98 examples/s]Map:  18%|█▊        | 18523/104743 [00:10<00:46, 1845.19 examples/s]Map:  18%|█▊        | 18783/104743 [00:10<00:42, 2010.75 examples/s]Map:  18%|█▊        | 19132/104743 [00:10<00:52, 1641.58 examples/s]Map:  19%|█▊        | 19394/104743 [00:10<00:46, 1827.28 examples/s]Map:  19%|█▉        | 19647/104743 [00:10<00:43, 1977.42 examples/s]Map:  19%|█▉        | 19909/104743 [00:10<00:39, 2127.74 examples/s]Map:  19%|█▉        | 20263/104743 [00:11<00:50, 1684.83 examples/s]Map:  20%|█▉        | 20525/104743 [00:11<00:45, 1866.72 examples/s]Map:  20%|█▉        | 20791/104743 [00:11<00:41, 2038.20 examples/s]Map:  20%|██        | 21134/104743 [00:11<00:51, 1625.47 examples/s]Map:  20%|██        | 21394/104743 [00:11<00:46, 1808.47 examples/s]Map:  21%|██        | 21654/104743 [00:11<00:42, 1974.18 examples/s]Map:  21%|██        | 21918/104743 [00:12<00:38, 2126.71 examples/s]Map:  21%|██▏       | 22265/104743 [00:12<00:48, 1690.73 examples/s]Map:  22%|██▏       | 22527/104743 [00:12<00:43, 1871.17 examples/s]Map:  22%|██▏       | 22782/104743 [00:12<00:40, 2018.13 examples/s]Map:  22%|██▏       | 23132/104743 [00:12<00:49, 1639.31 examples/s]Map:  22%|██▏       | 23398/104743 [00:12<00:44, 1832.53 examples/s]Map:  23%|██▎       | 23662/104743 [00:13<00:40, 2002.62 examples/s]Map:  23%|██▎       | 23908/104743 [00:13<00:38, 2107.17 examples/s]Map:  23%|██▎       | 24149/104743 [00:13<01:00, 1321.30 examples/s]Map:  23%|██▎       | 24410/104743 [00:13<00:51, 1548.81 examples/s]Map:  24%|██▎       | 24671/104743 [00:13<00:45, 1762.19 examples/s]Map:  24%|██▍       | 24934/104743 [00:13<00:40, 1954.97 examples/s]Map:  24%|██▍       | 25263/104743 [00:14<00:49, 1591.74 examples/s]Map:  24%|██▍       | 25522/104743 [00:14<00:44, 1785.40 examples/s]Map:  25%|██▍       | 25776/104743 [00:14<00:40, 1947.08 examples/s]Map:  25%|██▍       | 26131/104743 [00:14<00:48, 1606.65 examples/s]Map:  25%|██▌       | 26391/104743 [00:14<00:43, 1793.86 examples/s]Map:  25%|██▌       | 26652/104743 [00:14<00:39, 1966.05 examples/s]Map:  26%|██▌       | 26911/104743 [00:14<00:36, 2111.13 examples/s]Map:  26%|██▌       | 27264/104743 [00:15<00:46, 1657.43 examples/s]Map:  26%|██▋       | 27525/104743 [00:15<00:41, 1841.08 examples/s]Map:  27%|██▋       | 27786/104743 [00:15<00:38, 2005.14 examples/s]Map:  27%|██▋       | 28132/104743 [00:15<00:46, 1631.89 examples/s]Map:  27%|██▋       | 28390/104743 [00:15<00:42, 1811.62 examples/s]Map:  27%|██▋       | 28644/104743 [00:15<00:38, 1965.11 examples/s]Map:  28%|██▊       | 28907/104743 [00:15<00:35, 2118.49 examples/s]Map:  28%|██▊       | 29261/104743 [00:16<00:44, 1691.15 examples/s]Map:  28%|██▊       | 29522/104743 [00:16<00:40, 1870.61 examples/s]Map:  28%|██▊       | 29784/104743 [00:16<00:36, 2033.03 examples/s]Map:  29%|██▉       | 30132/104743 [00:16<00:45, 1622.26 examples/s]Map:  29%|██▉       | 30395/104743 [00:16<00:41, 1810.18 examples/s]Map:  29%|██▉       | 30656/104743 [00:16<00:37, 1978.39 examples/s]Map:  30%|██▉       | 30917/104743 [00:17<00:34, 2123.90 examples/s]Map:  30%|██▉       | 31266/104743 [00:17<00:43, 1693.37 examples/s]Map:  30%|███       | 31526/104743 [00:17<00:39, 1869.69 examples/s]Map:  30%|███       | 31780/104743 [00:17<00:36, 2014.25 examples/s]Map:  31%|███       | 32132/104743 [00:17<00:44, 1630.44 examples/s]Map:  31%|███       | 32393/104743 [00:17<00:39, 1814.81 examples/s]Map:  31%|███       | 32651/104743 [00:18<00:36, 1976.61 examples/s]Map:  31%|███▏      | 32908/104743 [00:18<00:34, 2112.74 examples/s]Map:  32%|███▏      | 33250/104743 [00:18<00:43, 1641.33 examples/s]Map:  32%|███▏      | 33506/104743 [00:18<00:39, 1818.04 examples/s]Map:  32%|███▏      | 33763/104743 [00:18<00:35, 1980.15 examples/s]Map:  32%|███▏      | 34000/104743 [00:18<00:46, 1530.57 examples/s]Map:  33%|███▎      | 34265/104743 [00:18<00:40, 1752.06 examples/s]Map:  33%|███▎      | 34526/104743 [00:19<00:36, 1940.98 examples/s]Map:  33%|███▎      | 34781/104743 [00:19<00:33, 2084.75 examples/s]Map:  34%|███▎      | 35136/104743 [00:19<00:41, 1667.05 examples/s]Map:  34%|███▍      | 35397/104743 [00:19<00:37, 1853.28 examples/s]Map:  34%|███▍      | 35661/104743 [00:19<00:34, 2025.64 examples/s]Map:  34%|███▍      | 35922/104743 [00:19<00:31, 2163.19 examples/s]Map:  35%|███▍      | 36263/104743 [00:20<00:41, 1660.88 examples/s]Map:  35%|███▍      | 36523/104743 [00:20<00:36, 1844.03 examples/s]Map:  35%|███▌      | 36786/104743 [00:20<00:33, 2012.68 examples/s]Map:  35%|███▌      | 37128/104743 [00:20<00:41, 1634.34 examples/s]Map:  36%|███▌      | 37393/104743 [00:20<00:36, 1826.74 examples/s]Map:  36%|███▌      | 37648/104743 [00:20<00:33, 1979.87 examples/s]Map:  36%|███▌      | 37909/104743 [00:20<00:31, 2124.70 examples/s]Map:  37%|███▋      | 38263/104743 [00:21<00:39, 1674.64 examples/s]Map:  37%|███▋      | 38525/104743 [00:21<00:35, 1857.93 examples/s]Map:  37%|███▋      | 38787/104743 [00:21<00:32, 2022.22 examples/s]Map:  37%|███▋      | 39132/104743 [00:21<00:40, 1628.32 examples/s]Map:  38%|███▊      | 39390/104743 [00:21<00:36, 1806.98 examples/s]Map:  38%|███▊      | 39651/104743 [00:21<00:32, 1977.34 examples/s]Map:  38%|███▊      | 39913/104743 [00:21<00:30, 2126.23 examples/s]Map:  38%|███▊      | 40267/104743 [00:22<00:38, 1693.09 examples/s]Map:  39%|███▊      | 40530/104743 [00:22<00:34, 1875.73 examples/s]Map:  39%|███▉      | 40783/104743 [00:22<00:31, 2017.54 examples/s]Map:  39%|███▉      | 41131/104743 [00:22<00:38, 1636.86 examples/s]Map:  40%|███▉      | 41395/104743 [00:22<00:34, 1827.37 examples/s]Map:  40%|███▉      | 41660/104743 [00:22<00:31, 2001.89 examples/s]Map:  40%|████      | 41924/104743 [00:22<00:29, 2149.23 examples/s]Map:  40%|████      | 42277/104743 [00:23<00:43, 1435.08 examples/s]Map:  41%|████      | 42536/104743 [00:23<00:38, 1631.13 examples/s]Map:  41%|████      | 42799/104743 [00:23<00:33, 1825.29 examples/s]Map:  41%|████      | 43134/104743 [00:23<00:39, 1555.58 examples/s]Map:  41%|████▏     | 43397/104743 [00:23<00:35, 1751.24 examples/s]Map:  42%|████▏     | 43654/104743 [00:24<00:31, 1919.24 examples/s]Map:  42%|████▏     | 43917/104743 [00:24<00:29, 2080.16 examples/s]Map:  42%|████▏     | 44263/104743 [00:24<00:36, 1660.39 examples/s]Map:  43%|████▎     | 44524/104743 [00:24<00:32, 1842.59 examples/s]Map:  43%|████▎     | 44783/104743 [00:24<00:29, 2003.54 examples/s]Map:  43%|████▎     | 45129/104743 [00:24<00:37, 1582.56 examples/s]Map:  43%|████▎     | 45389/104743 [00:25<00:33, 1770.30 examples/s]Map:  44%|████▎     | 45654/104743 [00:25<00:30, 1953.54 examples/s]Map:  44%|████▍     | 45912/104743 [00:25<00:28, 2095.40 examples/s]Map:  44%|████▍     | 46267/104743 [00:25<00:34, 1682.61 examples/s]Map:  44%|████▍     | 46529/104743 [00:25<00:31, 1863.95 examples/s]Map:  45%|████▍     | 46784/104743 [00:25<00:28, 2011.07 examples/s]Map:  45%|████▍     | 47134/104743 [00:26<00:35, 1641.19 examples/s]Map:  45%|████▌     | 47392/104743 [00:26<00:31, 1818.53 examples/s]Map:  45%|████▌     | 47656/104743 [00:26<00:28, 1991.97 examples/s]Map:  46%|████▌     | 47916/104743 [00:26<00:26, 2132.02 examples/s]Map:  46%|████▌     | 48263/104743 [00:26<00:33, 1664.94 examples/s]Map:  46%|████▋     | 48522/104743 [00:26<00:30, 1844.19 examples/s]Map:  47%|████▋     | 48781/104743 [00:26<00:27, 2004.87 examples/s]Map:  47%|████▋     | 49132/104743 [00:27<00:33, 1638.17 examples/s]Map:  47%|████▋     | 49392/104743 [00:27<00:30, 1819.81 examples/s]Map:  47%|████▋     | 49648/104743 [00:27<00:27, 1976.24 examples/s]Map:  48%|████▊     | 49913/104743 [00:27<00:25, 2131.10 examples/s]Map:  48%|████▊     | 50263/104743 [00:27<00:32, 1680.62 examples/s]Map:  48%|████▊     | 50524/104743 [00:27<00:29, 1861.42 examples/s]Map:  48%|████▊     | 50791/104743 [00:27<00:26, 2035.84 examples/s]Map:  49%|████▉     | 51133/104743 [00:28<00:32, 1634.76 examples/s]Map:  49%|████▉     | 51395/104743 [00:28<00:29, 1819.19 examples/s]Map:  49%|████▉     | 51655/104743 [00:28<00:26, 1984.01 examples/s]Map:  50%|████▉     | 51917/104743 [00:28<00:24, 2129.64 examples/s]Map:  50%|████▉     | 52265/104743 [00:28<00:31, 1685.93 examples/s]Map:  50%|█████     | 52530/104743 [00:28<00:27, 1872.80 examples/s]Map:  50%|█████     | 52785/104743 [00:28<00:25, 2019.09 examples/s]Map:  51%|█████     | 53131/104743 [00:29<00:31, 1636.30 examples/s]Map:  51%|█████     | 53395/104743 [00:29<00:28, 1826.23 examples/s]Map:  51%|█████     | 53658/104743 [00:29<00:25, 1996.82 examples/s]Map:  51%|█████▏    | 53917/104743 [00:29<00:23, 2133.65 examples/s]Map:  52%|█████▏    | 54267/104743 [00:29<00:30, 1669.71 examples/s]Map:  52%|█████▏    | 54527/104743 [00:29<00:27, 1848.77 examples/s]Map:  52%|█████▏    | 54786/104743 [00:30<00:24, 2008.51 examples/s]Map:  53%|█████▎    | 55135/104743 [00:30<00:30, 1644.57 examples/s]Map:  53%|█████▎    | 55397/104743 [00:30<00:26, 1829.78 examples/s]Map:  53%|█████▎    | 55651/104743 [00:30<00:24, 1981.22 examples/s]Map:  53%|█████▎    | 55911/104743 [00:30<00:22, 2124.23 examples/s]Map:  54%|█████▎    | 56264/104743 [00:30<00:28, 1690.52 examples/s]Map:  54%|█████▍    | 56528/104743 [00:31<00:25, 1874.80 examples/s]Map:  54%|█████▍    | 56790/104743 [00:31<00:23, 2035.99 examples/s]Map:  55%|█████▍    | 57134/104743 [00:31<00:29, 1630.38 examples/s]Map:  55%|█████▍    | 57396/104743 [00:31<00:26, 1817.10 examples/s]Map:  55%|█████▌    | 57659/104743 [00:31<00:23, 1989.70 examples/s]Map:  55%|█████▌    | 57921/104743 [00:31<00:21, 2135.34 examples/s]Map:  56%|█████▌    | 58262/104743 [00:31<00:27, 1680.77 examples/s]Map:  56%|█████▌    | 58527/104743 [00:32<00:24, 1869.98 examples/s]Map:  56%|█████▌    | 58779/104743 [00:32<00:22, 2011.03 examples/s]Map:  56%|█████▋    | 59132/104743 [00:32<00:27, 1641.27 examples/s]Map:  57%|█████▋    | 59395/104743 [00:32<00:24, 1827.47 examples/s]Map:  57%|█████▋    | 59659/104743 [00:32<00:22, 1999.49 examples/s]Map:  57%|█████▋    | 59920/104743 [00:32<00:20, 2139.89 examples/s]Map:  58%|█████▊    | 60279/104743 [00:33<00:31, 1427.49 examples/s]Map:  58%|█████▊    | 60540/104743 [00:33<00:27, 1626.57 examples/s]Map:  58%|█████▊    | 60795/104743 [00:33<00:24, 1804.67 examples/s]Map:  58%|█████▊    | 61130/104743 [00:33<00:28, 1531.47 examples/s]Map:  59%|█████▊    | 61392/104743 [00:33<00:25, 1729.14 examples/s]Map:  59%|█████▉    | 61646/104743 [00:33<00:22, 1894.95 examples/s]Map:  59%|█████▉    | 61909/104743 [00:33<00:20, 2059.12 examples/s]Map:  59%|█████▉    | 62262/104743 [00:34<00:25, 1660.55 examples/s]Map:  60%|█████▉    | 62522/104743 [00:34<00:22, 1841.24 examples/s]Map:  60%|█████▉    | 62787/104743 [00:34<00:20, 2013.29 examples/s]Map:  60%|██████    | 63131/104743 [00:34<00:25, 1614.52 examples/s]Map:  61%|██████    | 63394/104743 [00:34<00:22, 1803.28 examples/s]Map:  61%|██████    | 63616/104743 [00:34<00:21, 1890.07 examples/s]Map:  61%|██████    | 63932/104743 [00:35<00:20, 1954.83 examples/s]Map:  61%|██████▏   | 64229/104743 [00:36<01:08, 589.77 examples/s] Map:  62%|██████▏   | 64484/104743 [00:36<00:53, 748.33 examples/s]Map:  62%|██████▏   | 64743/104743 [00:36<00:42, 938.80 examples/s]Map:  62%|██████▏   | 65000/104743 [00:36<00:41, 959.68 examples/s]Map:  62%|██████▏   | 65264/104743 [00:36<00:33, 1182.92 examples/s]Map:  63%|██████▎   | 65525/104743 [00:37<00:27, 1410.16 examples/s]Map:  63%|██████▎   | 65786/104743 [00:37<00:23, 1631.70 examples/s]Map:  63%|██████▎   | 66134/104743 [00:37<00:26, 1442.23 examples/s]Map:  63%|██████▎   | 66397/104743 [00:37<00:23, 1650.36 examples/s]Map:  64%|██████▎   | 66658/104743 [00:37<00:20, 1842.12 examples/s]Map:  64%|██████▍   | 66922/104743 [00:37<00:18, 2019.26 examples/s]Map:  64%|██████▍   | 67265/104743 [00:38<00:22, 1644.95 examples/s]Map:  64%|██████▍   | 67525/104743 [00:38<00:20, 1829.44 examples/s]Map:  65%|██████▍   | 67782/104743 [00:38<00:18, 1987.76 examples/s]Map:  65%|██████▌   | 68133/104743 [00:38<00:22, 1624.08 examples/s]Map:  65%|██████▌   | 68391/104743 [00:38<00:20, 1803.94 examples/s]Map:  66%|██████▌   | 68655/104743 [00:38<00:18, 1979.77 examples/s]Map:  66%|██████▌   | 68918/104743 [00:38<00:16, 2128.49 examples/s]Map:  66%|██████▌   | 69262/104743 [00:39<00:21, 1647.95 examples/s]Map:  66%|██████▋   | 69523/104743 [00:39<00:19, 1832.96 examples/s]Map:  67%|██████▋   | 69785/104743 [00:39<00:17, 2000.64 examples/s]Map:  67%|██████▋   | 70129/104743 [00:39<00:21, 1633.80 examples/s]Map:  67%|██████▋   | 70388/104743 [00:39<00:18, 1815.60 examples/s]Map:  67%|██████▋   | 70644/104743 [00:39<00:17, 1972.38 examples/s]Map:  68%|██████▊   | 70905/104743 [00:39<00:15, 2120.20 examples/s]Map:  68%|██████▊   | 71266/104743 [00:40<00:19, 1684.85 examples/s]Map:  68%|██████▊   | 71529/104743 [00:40<00:17, 1867.51 examples/s]Map:  69%|██████▊   | 71787/104743 [00:40<00:16, 2020.39 examples/s]Map:  69%|██████▉   | 72133/104743 [00:40<00:20, 1627.41 examples/s]Map:  69%|██████▉   | 72397/104743 [00:40<00:17, 1817.04 examples/s]Map:  69%|██████▉   | 72658/104743 [00:40<00:16, 1983.79 examples/s]Map:  70%|██████▉   | 72919/104743 [00:40<00:14, 2126.10 examples/s]Map:  70%|██████▉   | 73264/104743 [00:41<00:18, 1673.61 examples/s]Map:  70%|███████   | 73526/104743 [00:41<00:16, 1857.27 examples/s]Map:  70%|███████   | 73780/104743 [00:41<00:15, 2005.58 examples/s]Map:  71%|███████   | 74134/104743 [00:41<00:18, 1644.51 examples/s]Map:  71%|███████   | 74395/104743 [00:41<00:16, 1827.79 examples/s]Map:  71%|███████▏  | 74656/104743 [00:41<00:15, 1992.85 examples/s]Map:  72%|███████▏  | 74918/104743 [00:42<00:13, 2137.28 examples/s]Map:  72%|███████▏  | 75263/104743 [00:42<00:17, 1656.38 examples/s]Map:  72%|███████▏  | 75525/104743 [00:42<00:15, 1841.70 examples/s]Map:  72%|███████▏  | 75786/104743 [00:42<00:14, 2005.96 examples/s]Map:  73%|███████▎  | 76133/104743 [00:42<00:17, 1642.58 examples/s]Map:  73%|███████▎  | 76393/104743 [00:42<00:15, 1823.83 examples/s]Map:  73%|███████▎  | 76649/104743 [00:43<00:14, 1979.14 examples/s]Map:  73%|███████▎  | 76911/104743 [00:43<00:13, 2126.74 examples/s]Map:  74%|███████▍  | 77263/104743 [00:43<00:16, 1676.31 examples/s]Map:  74%|███████▍  | 77527/104743 [00:43<00:14, 1862.98 examples/s]Map:  74%|███████▍  | 77785/104743 [00:43<00:13, 2018.38 examples/s]Map:  75%|███████▍  | 78129/104743 [00:43<00:16, 1588.62 examples/s]Map:  75%|███████▍  | 78410/104743 [00:44<00:17, 1512.20 examples/s]Map:  75%|███████▌  | 78673/104743 [00:44<00:15, 1712.98 examples/s]Map:  75%|███████▌  | 78935/104743 [00:44<00:13, 1898.33 examples/s]Map:  76%|███████▌  | 79265/104743 [00:44<00:16, 1566.87 examples/s]Map:  76%|███████▌  | 79526/104743 [00:44<00:14, 1760.32 examples/s]Map:  76%|███████▌  | 79781/104743 [00:44<00:12, 1923.74 examples/s]Map:  77%|███████▋  | 80132/104743 [00:45<00:15, 1600.92 examples/s]Map:  77%|███████▋  | 80396/104743 [00:45<00:13, 1794.68 examples/s]Map:  77%|███████▋  | 80658/104743 [00:45<00:12, 1967.46 examples/s]Map:  77%|███████▋  | 80919/104743 [00:45<00:11, 2112.45 examples/s]Map:  78%|███████▊  | 81262/104743 [00:45<00:14, 1646.72 examples/s]Map:  78%|███████▊  | 81525/104743 [00:45<00:12, 1834.93 examples/s]Map:  78%|███████▊  | 81787/104743 [00:45<00:11, 2003.25 examples/s]Map:  78%|███████▊  | 82133/104743 [00:46<00:13, 1633.82 examples/s]Map:  79%|███████▊  | 82397/104743 [00:46<00:12, 1824.64 examples/s]Map:  79%|███████▉  | 82644/104743 [00:46<00:11, 1959.65 examples/s]Map:  79%|███████▉  | 82905/104743 [00:46<00:10, 2110.33 examples/s]Map:  79%|███████▉  | 83265/104743 [00:46<00:12, 1676.45 examples/s]Map:  80%|███████▉  | 83525/104743 [00:46<00:11, 1855.32 examples/s]Map:  80%|███████▉  | 83786/104743 [00:46<00:10, 2016.72 examples/s]Map:  80%|████████  | 84133/104743 [00:47<00:12, 1627.71 examples/s]Map:  81%|████████  | 84392/104743 [00:47<00:11, 1808.01 examples/s]Map:  81%|████████  | 84656/104743 [00:47<00:10, 1983.24 examples/s]Map:  81%|████████  | 84917/104743 [00:47<00:09, 2127.04 examples/s]Map:  81%|████████▏ | 85266/104743 [00:47<00:11, 1674.81 examples/s]Map:  82%|████████▏ | 85533/104743 [00:47<00:10, 1866.82 examples/s]Map:  82%|████████▏ | 85786/104743 [00:48<00:09, 2009.98 examples/s]Map:  82%|████████▏ | 86132/104743 [00:48<00:11, 1639.73 examples/s]Map:  82%|████████▏ | 86391/104743 [00:48<00:10, 1820.80 examples/s]Map:  83%|████████▎ | 86653/104743 [00:48<00:09, 1990.57 examples/s]Map:  83%|████████▎ | 86914/104743 [00:48<00:08, 2134.70 examples/s]Map:  83%|████████▎ | 87267/104743 [00:48<00:10, 1663.58 examples/s]Map:  84%|████████▎ | 87527/104743 [00:49<00:09, 1843.22 examples/s]Map:  84%|████████▍ | 87788/104743 [00:49<00:08, 2006.60 examples/s]Map:  84%|████████▍ | 88132/104743 [00:49<00:10, 1637.21 examples/s]Map:  84%|████████▍ | 88394/104743 [00:49<00:08, 1823.76 examples/s]Map:  85%|████████▍ | 88645/104743 [00:49<00:08, 1968.55 examples/s]Map:  85%|████████▍ | 88903/104743 [00:49<00:07, 2111.19 examples/s]Map:  85%|████████▌ | 89263/104743 [00:50<00:09, 1674.22 examples/s]Map:  85%|████████▌ | 89525/104743 [00:50<00:08, 1856.45 examples/s]Map:  86%|████████▌ | 89788/104743 [00:50<00:07, 2023.16 examples/s]Map:  86%|████████▌ | 90134/104743 [00:50<00:08, 1628.08 examples/s]Map:  86%|████████▋ | 90397/104743 [00:50<00:07, 1816.84 examples/s]Map:  87%|████████▋ | 90658/104743 [00:50<00:07, 1983.29 examples/s]Map:  87%|████████▋ | 90921/104743 [00:50<00:06, 2130.94 examples/s]Map:  87%|████████▋ | 91264/104743 [00:51<00:08, 1676.81 examples/s]Map:  87%|████████▋ | 91526/104743 [00:51<00:07, 1860.33 examples/s]Map:  88%|████████▊ | 91779/104743 [00:51<00:06, 2004.92 examples/s]Map:  88%|████████▊ | 92134/104743 [00:51<00:07, 1643.37 examples/s]Map:  88%|████████▊ | 92396/104743 [00:51<00:06, 1827.39 examples/s]Map:  88%|████████▊ | 92658/104743 [00:51<00:06, 1996.00 examples/s]Map:  89%|████████▊ | 92918/104743 [00:51<00:05, 2134.54 examples/s]Map:  89%|████████▉ | 93263/104743 [00:52<00:06, 1663.55 examples/s]Map:  89%|████████▉ | 93525/104743 [00:52<00:06, 1847.40 examples/s]Map:  90%|████████▉ | 93785/104743 [00:52<00:05, 2008.75 examples/s]Map:  90%|████████▉ | 94132/104743 [00:52<00:06, 1639.06 examples/s]Map:  90%|█████████ | 94394/104743 [00:52<00:05, 1824.02 examples/s]Map:  90%|█████████ | 94648/104743 [00:52<00:05, 1975.42 examples/s]Map:  91%|█████████ | 94908/104743 [00:52<00:04, 2118.39 examples/s]Map:  91%|█████████ | 95264/104743 [00:53<00:05, 1682.82 examples/s]Map:  91%|█████████ | 95520/104743 [00:53<00:04, 1853.22 examples/s]Map:  91%|█████████▏| 95782/104743 [00:53<00:04, 2018.97 examples/s]Map:  92%|█████████▏| 96132/104743 [00:53<00:05, 1627.06 examples/s]Map:  92%|█████████▏| 96406/104743 [00:53<00:05, 1602.50 examples/s]Map:  92%|█████████▏| 96667/104743 [00:54<00:04, 1792.95 examples/s]Map:  93%|█████████▎| 96927/104743 [00:54<00:03, 1963.33 examples/s]Map:  93%|█████████▎| 97265/104743 [00:54<00:04, 1613.57 examples/s]Map:  93%|█████████▎| 97528/104743 [00:54<00:03, 1805.54 examples/s]Map:  93%|█████████▎| 97782/104743 [00:54<00:03, 1959.84 examples/s]Map:  94%|█████████▎| 98134/104743 [00:54<00:04, 1626.74 examples/s]Map:  94%|█████████▍| 98396/104743 [00:54<00:03, 1814.23 examples/s]Map:  94%|█████████▍| 98657/104743 [00:55<00:03, 1982.79 examples/s]Map:  94%|█████████▍| 98920/104743 [00:55<00:02, 2131.43 examples/s]Map:  95%|█████████▍| 99268/104743 [00:55<00:03, 1664.83 examples/s]Map:  95%|█████████▌| 99528/104743 [00:55<00:02, 1843.75 examples/s]Map:  95%|█████████▌| 99789/104743 [00:55<00:02, 2009.17 examples/s]Map:  96%|█████████▌| 100133/104743 [00:55<00:02, 1635.87 examples/s]Map:  96%|█████████▌| 100397/104743 [00:56<00:02, 1826.42 examples/s]Map:  96%|█████████▌| 100652/104743 [00:56<00:02, 1980.79 examples/s]Map:  96%|█████████▋| 100911/104743 [00:56<00:01, 2120.60 examples/s]Map:  97%|█████████▋| 101263/104743 [00:56<00:02, 1681.55 examples/s]Map:  97%|█████████▋| 101515/104743 [00:56<00:01, 1843.57 examples/s]Map:  97%|█████████▋| 101766/104743 [00:56<00:01, 1988.27 examples/s]Map:  97%|█████████▋| 102000/104743 [00:57<00:01, 1505.92 examples/s]Map:  98%|█████████▊| 102267/104743 [00:57<00:01, 1734.48 examples/s]Map:  98%|█████████▊| 102532/104743 [00:57<00:01, 1932.05 examples/s]Map:  98%|█████████▊| 102793/104743 [00:57<00:00, 2092.45 examples/s]Map:  98%|█████████▊| 103132/104743 [00:57<00:00, 1661.99 examples/s]Map:  99%|█████████▊| 103394/104743 [00:57<00:00, 1851.65 examples/s]Map:  99%|█████████▉| 103650/104743 [00:57<00:00, 2006.93 examples/s]Map:  99%|█████████▉| 103911/104743 [00:57<00:00, 2151.31 examples/s]Map: 100%|█████████▉| 104264/104743 [00:58<00:00, 1685.36 examples/s]Map: 100%|█████████▉| 104527/104743 [00:58<00:00, 1870.32 examples/s]                                                                     Map:   0%|          | 0/5463 [00:00<?, ? examples/s]Map:   3%|▎         | 171/5463 [00:00<00:03, 1683.67 examples/s]Map:   7%|▋         | 364/5463 [00:00<00:02, 1820.15 examples/s]Map:  10%|█         | 557/5463 [00:00<00:02, 1866.18 examples/s]Map:  14%|█▎        | 750/5463 [00:00<00:02, 1887.34 examples/s]Map:  18%|█▊        | 978/5463 [00:00<00:02, 2024.67 examples/s]Map:  23%|██▎       | 1264/5463 [00:00<00:02, 1498.31 examples/s]Map:  28%|██▊       | 1525/5463 [00:00<00:02, 1762.71 examples/s]Map:  32%|███▏      | 1775/5463 [00:00<00:01, 1948.45 examples/s]Map:  37%|███▋      | 2000/5463 [00:01<00:02, 1482.53 examples/s]Map:  41%|████▏     | 2258/5463 [00:01<00:01, 1719.85 examples/s]Map:  46%|████▌     | 2517/5463 [00:01<00:01, 1923.22 examples/s]Map:  51%|█████     | 2776/5463 [00:01<00:01, 2089.82 examples/s]Map:  57%|█████▋    | 3133/5463 [00:01<00:01, 1656.39 examples/s]Map:  62%|██████▏   | 3391/5463 [00:01<00:01, 1840.48 examples/s]Map:  67%|██████▋   | 3651/5463 [00:01<00:00, 2008.93 examples/s]Map:  72%|███████▏  | 3911/5463 [00:02<00:00, 2150.92 examples/s]Map:  78%|███████▊  | 4261/5463 [00:02<00:00, 1686.43 examples/s]Map:  83%|████████▎ | 4524/5463 [00:02<00:00, 1871.59 examples/s]Map:  87%|████████▋ | 4774/5463 [00:02<00:00, 2007.20 examples/s]Map:  94%|█████████▍| 5130/5463 [00:02<00:00, 1633.21 examples/s]Map:  99%|█████████▊| 5390/5463 [00:02<00:00, 1816.14 examples/s]                                                                 /home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
{'loss': 0.6338, 'learning_rate': 2.5e-06, 'epoch': 0.15}
{'loss': 0.4495, 'learning_rate': 5e-06, 'epoch': 0.31}
{'loss': 0.3938, 'learning_rate': 7.5e-06, 'epoch': 0.46}
{'loss': 0.3605, 'learning_rate': 1e-05, 'epoch': 0.61}
{'loss': 0.3492, 'learning_rate': 1.25e-05, 'epoch': 0.76}
{'loss': 0.3271, 'learning_rate': 1.5e-05, 'epoch': 0.92}
{'eval_loss': 0.26482725143432617, 'eval_accuracy': 0.8925498810177558, 'eval_runtime': 165.4471, 'eval_samples_per_second': 33.02, 'eval_steps_per_second': 2.067, 'epoch': 1.0}
{'loss': 0.2894, 'learning_rate': 1.75e-05, 'epoch': 1.07}
{'loss': 0.2613, 'learning_rate': 2e-05, 'epoch': 1.22}
{'loss': 0.2622, 'learning_rate': 2.25e-05, 'epoch': 1.37}
{'loss': 0.2701, 'learning_rate': 2.5e-05, 'epoch': 1.53}
{'loss': 0.2757, 'learning_rate': 2.7500000000000004e-05, 'epoch': 1.68}
{'loss': 0.2717, 'learning_rate': 3e-05, 'epoch': 1.83}
{'loss': 0.2629, 'learning_rate': 3.2500000000000004e-05, 'epoch': 1.99}
{'eval_loss': 0.245132178068161, 'eval_accuracy': 0.9051803038623467, 'eval_runtime': 165.2987, 'eval_samples_per_second': 33.049, 'eval_steps_per_second': 2.069, 'epoch': 2.0}
{'loss': 0.1812, 'learning_rate': 3.5e-05, 'epoch': 2.14}
{'loss': 0.179, 'learning_rate': 3.7500000000000003e-05, 'epoch': 2.29}
{'loss': 0.1909, 'learning_rate': 4e-05, 'epoch': 2.44}
{'loss': 0.1967, 'learning_rate': 4.25e-05, 'epoch': 2.6}
{'loss': 0.215, 'learning_rate': 4.5e-05, 'epoch': 2.75}
{'loss': 0.2207, 'learning_rate': 4.75e-05, 'epoch': 2.9}
{'eval_loss': 0.26429229974746704, 'eval_accuracy': 0.9015193117334798, 'eval_runtime': 165.2939, 'eval_samples_per_second': 33.05, 'eval_steps_per_second': 2.069, 'epoch': 3.0}
{'loss': 0.1917, 'learning_rate': 5e-05, 'epoch': 3.05}
{'loss': 0.1491, 'learning_rate': 4.8900131984161904e-05, 'epoch': 3.21}
{'loss': 0.1485, 'learning_rate': 4.7800263968323806e-05, 'epoch': 3.36}
{'loss': 0.1534, 'learning_rate': 4.67003959524857e-05, 'epoch': 3.51}
{'loss': 0.1595, 'learning_rate': 4.56005279366476e-05, 'epoch': 3.67}
{'loss': 0.1674, 'learning_rate': 4.4500659920809504e-05, 'epoch': 3.82}
{'loss': 0.1544, 'learning_rate': 4.3400791904971405e-05, 'epoch': 3.97}
{'eval_loss': 0.35923823714256287, 'eval_accuracy': 0.894746476295076, 'eval_runtime': 166.245, 'eval_samples_per_second': 32.861, 'eval_steps_per_second': 2.057, 'epoch': 4.0}
{'loss': 0.1106, 'learning_rate': 4.230092388913331e-05, 'epoch': 4.12}
{'loss': 0.1088, 'learning_rate': 4.120105587329521e-05, 'epoch': 4.28}
{'loss': 0.1099, 'learning_rate': 4.01011878574571e-05, 'epoch': 4.43}
{'loss': 0.1061, 'learning_rate': 3.9001319841619005e-05, 'epoch': 4.58}
{'loss': 0.1126, 'learning_rate': 3.7901451825780906e-05, 'epoch': 4.73}
{'loss': 0.1126, 'learning_rate': 3.680158380994281e-05, 'epoch': 4.89}
{'eval_loss': 0.37742817401885986, 'eval_accuracy': 0.8934651290499726, 'eval_runtime': 167.5733, 'eval_samples_per_second': 32.601, 'eval_steps_per_second': 2.041, 'epoch': 5.0}
{'loss': 0.101, 'learning_rate': 3.570171579410471e-05, 'epoch': 5.04}
{'loss': 0.0673, 'learning_rate': 3.460184777826661e-05, 'epoch': 5.19}
{'loss': 0.0748, 'learning_rate': 3.3501979762428506e-05, 'epoch': 5.35}
{'loss': 0.076, 'learning_rate': 3.2402111746590414e-05, 'epoch': 5.5}
{'loss': 0.0796, 'learning_rate': 3.130224373075231e-05, 'epoch': 5.65}
{'loss': 0.0829, 'learning_rate': 3.020237571491421e-05, 'epoch': 5.8}
{'loss': 0.0762, 'learning_rate': 2.9102507699076116e-05, 'epoch': 5.96}
{'eval_loss': 0.4936262369155884, 'eval_accuracy': 0.8960278235401794, 'eval_runtime': 166.2725, 'eval_samples_per_second': 32.856, 'eval_steps_per_second': 2.057, 'epoch': 6.0}
{'loss': 0.0542, 'learning_rate': 2.8002639683238014e-05, 'epoch': 6.11}
{'loss': 0.0469, 'learning_rate': 2.6902771667399912e-05, 'epoch': 6.26}
{'loss': 0.0484, 'learning_rate': 2.5802903651561817e-05, 'epoch': 6.42}
{'loss': 0.0493, 'learning_rate': 2.4703035635723715e-05, 'epoch': 6.57}
{'loss': 0.0472, 'learning_rate': 2.3603167619885617e-05, 'epoch': 6.72}
{'loss': 0.0608, 'learning_rate': 2.2503299604047515e-05, 'epoch': 6.87}
{'eval_loss': 0.5765901803970337, 'eval_accuracy': 0.8985905180303863, 'eval_runtime': 166.0583, 'eval_samples_per_second': 32.898, 'eval_steps_per_second': 2.06, 'epoch': 7.0}
{'loss': 0.0488, 'learning_rate': 2.1403431588209417e-05, 'epoch': 7.03}
{'loss': 0.0269, 'learning_rate': 2.030356357237132e-05, 'epoch': 7.18}
{'loss': 0.033, 'learning_rate': 1.9203695556533217e-05, 'epoch': 7.33}
{'loss': 0.0306, 'learning_rate': 1.8103827540695118e-05, 'epoch': 7.48}
{'loss': 0.0328, 'learning_rate': 1.700395952485702e-05, 'epoch': 7.64}
{'loss': 0.0264, 'learning_rate': 1.5904091509018918e-05, 'epoch': 7.79}
{'loss': 0.0316, 'learning_rate': 1.480422349318082e-05, 'epoch': 7.94}
{'eval_loss': 0.6521211862564087, 'eval_accuracy': 0.8991396668497162, 'eval_runtime': 166.0629, 'eval_samples_per_second': 32.897, 'eval_steps_per_second': 2.059, 'epoch': 8.0}
{'loss': 0.0207, 'learning_rate': 1.370435547734272e-05, 'epoch': 8.1}
{'loss': 0.014, 'learning_rate': 1.260448746150462e-05, 'epoch': 8.25}
{'loss': 0.0176, 'learning_rate': 1.1504619445666521e-05, 'epoch': 8.4}
{'loss': 0.0159, 'learning_rate': 1.0404751429828421e-05, 'epoch': 8.55}
{'loss': 0.0185, 'learning_rate': 9.30488341399032e-06, 'epoch': 8.71}
{'loss': 0.0151, 'learning_rate': 8.205015398152222e-06, 'epoch': 8.86}
{'eval_loss': 0.696976363658905, 'eval_accuracy': 0.9055464030752334, 'eval_runtime': 166.0909, 'eval_samples_per_second': 32.892, 'eval_steps_per_second': 2.059, 'epoch': 9.0}
{'loss': 0.0128, 'learning_rate': 7.105147382314123e-06, 'epoch': 9.01}
{'loss': 0.006, 'learning_rate': 6.005279366476023e-06, 'epoch': 9.16}
{'loss': 0.0062, 'learning_rate': 4.905411350637924e-06, 'epoch': 9.32}
{'loss': 0.0069, 'learning_rate': 3.805543334799824e-06, 'epoch': 9.47}
{'loss': 0.0078, 'learning_rate': 2.7056753189617244e-06, 'epoch': 9.62}
{'loss': 0.0059, 'learning_rate': 1.6058073031236254e-06, 'epoch': 9.78}
{'loss': 0.005, 'learning_rate': 5.059392872855257e-07, 'epoch': 9.93}
{'eval_loss': 0.7782610654830933, 'eval_accuracy': 0.9046311550430166, 'eval_runtime': 166.102, 'eval_samples_per_second': 32.889, 'eval_steps_per_second': 2.059, 'epoch': 10.0}
{'train_runtime': 95345.5051, 'train_samples_per_second': 10.986, 'train_steps_per_second': 0.343, 'train_loss': 0.1317942356138174, 'epoch': 10.0}
Total training time: 95345.54 seconds
######################################################################
layer-wise fine-tuning top 1
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 187.18it/s]
Map:   0%|          | 0/5463 [00:00<?, ? examples/s]Map:   2%|▏         | 111/5463 [00:00<00:04, 1096.80 examples/s]Map:   6%|▌         | 307/5463 [00:00<00:03, 1598.07 examples/s]Map:   9%|▉         | 501/5463 [00:00<00:02, 1749.33 examples/s]Map:  13%|█▎        | 700/5463 [00:00<00:02, 1839.91 examples/s]Map:  17%|█▋        | 905/5463 [00:00<00:02, 1912.50 examples/s]Map:  21%|██        | 1122/5463 [00:00<00:03, 1177.52 examples/s]Map:  25%|██▌       | 1375/5463 [00:00<00:02, 1475.31 examples/s]Map:  30%|██▉       | 1626/5463 [00:01<00:02, 1721.00 examples/s]Map:  34%|███▍      | 1882/5463 [00:01<00:01, 1932.77 examples/s]Map:  39%|███▉      | 2130/5463 [00:01<00:02, 1475.07 examples/s]Map:  44%|████▎     | 2385/5463 [00:01<00:01, 1701.53 examples/s]Map:  48%|████▊     | 2640/5463 [00:01<00:01, 1897.28 examples/s]Map:  53%|█████▎    | 2897/5463 [00:01<00:01, 2063.42 examples/s]Map:  57%|█████▋    | 3132/5463 [00:01<00:01, 1514.98 examples/s]Map:  62%|██████▏   | 3386/5463 [00:02<00:01, 1728.82 examples/s]Map:  67%|██████▋   | 3642/5463 [00:02<00:00, 1918.07 examples/s]Map:  71%|███████▏  | 3899/5463 [00:02<00:00, 2077.32 examples/s]Map:  78%|███████▊  | 4258/5463 [00:02<00:00, 1639.22 examples/s]Map:  83%|████████▎ | 4511/5463 [00:02<00:00, 1814.85 examples/s]Map:  87%|████████▋ | 4765/5463 [00:02<00:00, 1973.94 examples/s]Map:  92%|█████████▏| 5000/5463 [00:02<00:00, 1501.50 examples/s]Map:  96%|█████████▋| 5259/5463 [00:03<00:00, 1717.76 examples/s]                                                                 /home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.2', 'bert.encoder.layer.3', 'bert.encoder.layer.4', 'bert.encoder.layer.5', 'bert.encoder.layer.6', 'bert.encoder.layer.7', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
{'loss': 0.7623, 'learning_rate': 2.5e-06, 'epoch': 0.15}
{'loss': 0.6153, 'learning_rate': 5e-06, 'epoch': 0.31}
{'loss': 0.56, 'learning_rate': 7.5e-06, 'epoch': 0.46}
{'loss': 0.5058, 'learning_rate': 1e-05, 'epoch': 0.61}
{'loss': 0.4831, 'learning_rate': 1.25e-05, 'epoch': 0.76}
{'loss': 0.47, 'learning_rate': 1.5e-05, 'epoch': 0.92}
{'eval_loss': 0.4069618284702301, 'eval_accuracy': 0.8211605345048508, 'eval_runtime': 166.7083, 'eval_samples_per_second': 32.77, 'eval_steps_per_second': 2.051, 'epoch': 1.0}
{'loss': 0.4468, 'learning_rate': 1.75e-05, 'epoch': 1.07}
{'loss': 0.4311, 'learning_rate': 2e-05, 'epoch': 1.22}
{'loss': 0.4223, 'learning_rate': 2.25e-05, 'epoch': 1.37}
{'loss': 0.4136, 'learning_rate': 2.5e-05, 'epoch': 1.53}
{'loss': 0.416, 'learning_rate': 2.7500000000000004e-05, 'epoch': 1.68}
{'loss': 0.4045, 'learning_rate': 3e-05, 'epoch': 1.83}
{'loss': 0.385, 'learning_rate': 3.2500000000000004e-05, 'epoch': 1.99}
{'eval_loss': 0.34450265765190125, 'eval_accuracy': 0.8539264140582098, 'eval_runtime': 166.7993, 'eval_samples_per_second': 32.752, 'eval_steps_per_second': 2.05, 'epoch': 2.0}
{'loss': 0.346, 'learning_rate': 3.5e-05, 'epoch': 2.14}
{'loss': 0.341, 'learning_rate': 3.7500000000000003e-05, 'epoch': 2.29}
{'loss': 0.3438, 'learning_rate': 4e-05, 'epoch': 2.44}
{'loss': 0.3499, 'learning_rate': 4.25e-05, 'epoch': 2.6}
{'loss': 0.3432, 'learning_rate': 4.5e-05, 'epoch': 2.75}
{'loss': 0.3441, 'learning_rate': 4.75e-05, 'epoch': 2.9}
{'eval_loss': 0.3343271315097809, 'eval_accuracy': 0.8617975471352737, 'eval_runtime': 166.6307, 'eval_samples_per_second': 32.785, 'eval_steps_per_second': 2.052, 'epoch': 3.0}
{'loss': 0.3128, 'learning_rate': 5e-05, 'epoch': 3.05}
{'loss': 0.2705, 'learning_rate': 4.8900131984161904e-05, 'epoch': 3.21}
{'loss': 0.2613, 'learning_rate': 4.7800263968323806e-05, 'epoch': 3.36}
{'loss': 0.27, 'learning_rate': 4.67003959524857e-05, 'epoch': 3.51}
{'loss': 0.2712, 'learning_rate': 4.56005279366476e-05, 'epoch': 3.67}
{'loss': 0.2681, 'learning_rate': 4.4500659920809504e-05, 'epoch': 3.82}
{'loss': 0.26, 'learning_rate': 4.3400791904971405e-05, 'epoch': 3.97}
{'eval_loss': 0.3511101007461548, 'eval_accuracy': 0.8632619439868204, 'eval_runtime': 166.4714, 'eval_samples_per_second': 32.816, 'eval_steps_per_second': 2.054, 'epoch': 4.0}
{'loss': 0.1944, 'learning_rate': 4.230092388913331e-05, 'epoch': 4.12}
{'loss': 0.1789, 'learning_rate': 4.120105587329521e-05, 'epoch': 4.28}
{'loss': 0.1883, 'learning_rate': 4.01011878574571e-05, 'epoch': 4.43}
{'loss': 0.1873, 'learning_rate': 3.9001319841619005e-05, 'epoch': 4.58}
{'loss': 0.1884, 'learning_rate': 3.7901451825780906e-05, 'epoch': 4.73}
{'loss': 0.1862, 'learning_rate': 3.680158380994281e-05, 'epoch': 4.89}
{'eval_loss': 0.417441725730896, 'eval_accuracy': 0.8552077613033132, 'eval_runtime': 166.771, 'eval_samples_per_second': 32.757, 'eval_steps_per_second': 2.051, 'epoch': 5.0}
{'loss': 0.1758, 'learning_rate': 3.570171579410471e-05, 'epoch': 5.04}
{'loss': 0.12, 'learning_rate': 3.460184777826661e-05, 'epoch': 5.19}
{'loss': 0.1279, 'learning_rate': 3.3501979762428506e-05, 'epoch': 5.35}
{'loss': 0.1324, 'learning_rate': 3.2402111746590414e-05, 'epoch': 5.5}
{'loss': 0.1305, 'learning_rate': 3.130224373075231e-05, 'epoch': 5.65}
{'loss': 0.1424, 'learning_rate': 3.020237571491421e-05, 'epoch': 5.8}
{'loss': 0.1286, 'learning_rate': 2.9102507699076116e-05, 'epoch': 5.96}
{'eval_loss': 0.5018281936645508, 'eval_accuracy': 0.8531942156324364, 'eval_runtime': 166.5467, 'eval_samples_per_second': 32.802, 'eval_steps_per_second': 2.053, 'epoch': 6.0}
{'loss': 0.1081, 'learning_rate': 2.8002639683238014e-05, 'epoch': 6.11}
{'loss': 0.0933, 'learning_rate': 2.6902771667399912e-05, 'epoch': 6.26}
{'loss': 0.0912, 'learning_rate': 2.5802903651561817e-05, 'epoch': 6.42}
{'loss': 0.1026, 'learning_rate': 2.4703035635723715e-05, 'epoch': 6.57}
{'loss': 0.0989, 'learning_rate': 2.3603167619885617e-05, 'epoch': 6.72}
{'loss': 0.096, 'learning_rate': 2.2503299604047515e-05, 'epoch': 6.87}
{'eval_loss': 0.5819689631462097, 'eval_accuracy': 0.8533772652388797, 'eval_runtime': 166.5968, 'eval_samples_per_second': 32.792, 'eval_steps_per_second': 2.053, 'epoch': 7.0}
{'loss': 0.0954, 'learning_rate': 2.1403431588209417e-05, 'epoch': 7.03}
{'loss': 0.0653, 'learning_rate': 2.030356357237132e-05, 'epoch': 7.18}
{'loss': 0.0699, 'learning_rate': 1.9203695556533217e-05, 'epoch': 7.33}
{'loss': 0.0669, 'learning_rate': 1.8103827540695118e-05, 'epoch': 7.48}
{'loss': 0.0712, 'learning_rate': 1.700395952485702e-05, 'epoch': 7.64}
{'loss': 0.0734, 'learning_rate': 1.5904091509018918e-05, 'epoch': 7.79}
{'loss': 0.0741, 'learning_rate': 1.480422349318082e-05, 'epoch': 7.94}
{'eval_loss': 0.6531007289886475, 'eval_accuracy': 0.8519128683873329, 'eval_runtime': 166.5831, 'eval_samples_per_second': 32.794, 'eval_steps_per_second': 2.053, 'epoch': 8.0}
{'loss': 0.0601, 'learning_rate': 1.370435547734272e-05, 'epoch': 8.1}
{'loss': 0.0585, 'learning_rate': 1.260448746150462e-05, 'epoch': 8.25}
{'loss': 0.0523, 'learning_rate': 1.1504619445666521e-05, 'epoch': 8.4}
{'loss': 0.0516, 'learning_rate': 1.0404751429828421e-05, 'epoch': 8.55}
{'loss': 0.0638, 'learning_rate': 9.30488341399032e-06, 'epoch': 8.71}
{'loss': 0.0526, 'learning_rate': 8.205015398152222e-06, 'epoch': 8.86}
{'eval_loss': 0.7540274262428284, 'eval_accuracy': 0.8520959179937763, 'eval_runtime': 166.5868, 'eval_samples_per_second': 32.794, 'eval_steps_per_second': 2.053, 'epoch': 9.0}
{'loss': 0.0528, 'learning_rate': 7.105147382314123e-06, 'epoch': 9.01}
{'loss': 0.0445, 'learning_rate': 6.005279366476023e-06, 'epoch': 9.16}
{'loss': 0.0426, 'learning_rate': 4.905411350637924e-06, 'epoch': 9.32}
{'loss': 0.0433, 'learning_rate': 3.805543334799824e-06, 'epoch': 9.47}
{'loss': 0.048, 'learning_rate': 2.7056753189617244e-06, 'epoch': 9.62}
{'loss': 0.0461, 'learning_rate': 1.6058073031236254e-06, 'epoch': 9.78}
{'loss': 0.0455, 'learning_rate': 5.059392872855257e-07, 'epoch': 9.93}
{'eval_loss': 0.7886928915977478, 'eval_accuracy': 0.8508145707486728, 'eval_runtime': 166.6017, 'eval_samples_per_second': 32.791, 'eval_steps_per_second': 2.053, 'epoch': 10.0}
{'train_runtime': 75377.4189, 'train_samples_per_second': 13.896, 'train_steps_per_second': 0.434, 'train_loss': 0.21637575022496108, 'epoch': 10.0}
Total training time: 75377.44 seconds
######################################################################
layer-wise fine-tuning top 2
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 393.07it/s]
/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.2', 'bert.encoder.layer.4', 'bert.encoder.layer.5', 'bert.encoder.layer.6', 'bert.encoder.layer.7', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
{'loss': 0.7528, 'learning_rate': 2.5e-06, 'epoch': 0.15}
{'loss': 0.5754, 'learning_rate': 5e-06, 'epoch': 0.31}
{'loss': 0.5031, 'learning_rate': 7.5e-06, 'epoch': 0.46}
{'loss': 0.4652, 'learning_rate': 1e-05, 'epoch': 0.61}
{'loss': 0.4462, 'learning_rate': 1.25e-05, 'epoch': 0.76}
{'loss': 0.4317, 'learning_rate': 1.5e-05, 'epoch': 0.92}
{'eval_loss': 0.3599013686180115, 'eval_accuracy': 0.8480688266520227, 'eval_runtime': 167.1706, 'eval_samples_per_second': 32.679, 'eval_steps_per_second': 2.046, 'epoch': 1.0}
{'loss': 0.4058, 'learning_rate': 1.75e-05, 'epoch': 1.07}
{'loss': 0.3863, 'learning_rate': 2e-05, 'epoch': 1.22}
{'loss': 0.3743, 'learning_rate': 2.25e-05, 'epoch': 1.37}
{'loss': 0.3703, 'learning_rate': 2.5e-05, 'epoch': 1.53}
{'loss': 0.3708, 'learning_rate': 2.7500000000000004e-05, 'epoch': 1.68}
{'loss': 0.3642, 'learning_rate': 3e-05, 'epoch': 1.83}
{'loss': 0.3442, 'learning_rate': 3.2500000000000004e-05, 'epoch': 1.99}
{'eval_loss': 0.30623677372932434, 'eval_accuracy': 0.8720483250961011, 'eval_runtime': 166.7452, 'eval_samples_per_second': 32.763, 'eval_steps_per_second': 2.051, 'epoch': 2.0}
{'loss': 0.2919, 'learning_rate': 3.5e-05, 'epoch': 2.14}
{'loss': 0.2862, 'learning_rate': 3.7500000000000003e-05, 'epoch': 2.29}
{'loss': 0.2913, 'learning_rate': 4e-05, 'epoch': 2.44}
{'loss': 0.2943, 'learning_rate': 4.25e-05, 'epoch': 2.6}
{'loss': 0.2946, 'learning_rate': 4.5e-05, 'epoch': 2.75}
{'loss': 0.2996, 'learning_rate': 4.75e-05, 'epoch': 2.9}
{'eval_loss': 0.3072059750556946, 'eval_accuracy': 0.8735127219476478, 'eval_runtime': 166.8047, 'eval_samples_per_second': 32.751, 'eval_steps_per_second': 2.05, 'epoch': 3.0}
{'loss': 0.2557, 'learning_rate': 5e-05, 'epoch': 3.05}
{'loss': 0.2067, 'learning_rate': 4.8900131984161904e-05, 'epoch': 3.21}
{'loss': 0.2005, 'learning_rate': 4.7800263968323806e-05, 'epoch': 3.36}
{'loss': 0.2068, 'learning_rate': 4.67003959524857e-05, 'epoch': 3.51}
{'loss': 0.2096, 'learning_rate': 4.56005279366476e-05, 'epoch': 3.67}
{'loss': 0.2096, 'learning_rate': 4.4500659920809504e-05, 'epoch': 3.82}
{'loss': 0.2028, 'learning_rate': 4.3400791904971405e-05, 'epoch': 3.97}
{'eval_loss': 0.3256709575653076, 'eval_accuracy': 0.8753432180120813, 'eval_runtime': 166.7382, 'eval_samples_per_second': 32.764, 'eval_steps_per_second': 2.051, 'epoch': 4.0}
{'loss': 0.1343, 'learning_rate': 4.230092388913331e-05, 'epoch': 4.12}
{'loss': 0.1264, 'learning_rate': 4.120105587329521e-05, 'epoch': 4.28}
{'loss': 0.1309, 'learning_rate': 4.01011878574571e-05, 'epoch': 4.43}
{'loss': 0.124, 'learning_rate': 3.9001319841619005e-05, 'epoch': 4.58}
{'loss': 0.1308, 'learning_rate': 3.7901451825780906e-05, 'epoch': 4.73}
{'loss': 0.1284, 'learning_rate': 3.680158380994281e-05, 'epoch': 4.89}
{'eval_loss': 0.441238135099411, 'eval_accuracy': 0.8638110928061504, 'eval_runtime': 166.9386, 'eval_samples_per_second': 32.725, 'eval_steps_per_second': 2.049, 'epoch': 5.0}
{'loss': 0.1167, 'learning_rate': 3.570171579410471e-05, 'epoch': 5.04}
{'loss': 0.0717, 'learning_rate': 3.460184777826661e-05, 'epoch': 5.19}
{'loss': 0.087, 'learning_rate': 3.3501979762428506e-05, 'epoch': 5.35}
{'loss': 0.0852, 'learning_rate': 3.2402111746590414e-05, 'epoch': 5.5}
{'loss': 0.0833, 'learning_rate': 3.130224373075231e-05, 'epoch': 5.65}
{'loss': 0.0919, 'learning_rate': 3.020237571491421e-05, 'epoch': 5.8}
{'loss': 0.0821, 'learning_rate': 2.9102507699076116e-05, 'epoch': 5.96}
{'eval_loss': 0.47743046283721924, 'eval_accuracy': 0.8760754164378547, 'eval_runtime': 166.8402, 'eval_samples_per_second': 32.744, 'eval_steps_per_second': 2.05, 'epoch': 6.0}
{'loss': 0.0608, 'learning_rate': 2.8002639683238014e-05, 'epoch': 6.11}
{'loss': 0.0551, 'learning_rate': 2.6902771667399912e-05, 'epoch': 6.26}
{'loss': 0.0562, 'learning_rate': 2.5802903651561817e-05, 'epoch': 6.42}
{'loss': 0.0598, 'learning_rate': 2.4703035635723715e-05, 'epoch': 6.57}
{'loss': 0.0588, 'learning_rate': 2.3603167619885617e-05, 'epoch': 6.72}
{'loss': 0.0603, 'learning_rate': 2.2503299604047515e-05, 'epoch': 6.87}
{'eval_loss': 0.6190820336341858, 'eval_accuracy': 0.8769906644700713, 'eval_runtime': 166.831, 'eval_samples_per_second': 32.746, 'eval_steps_per_second': 2.05, 'epoch': 7.0}
{'loss': 0.0514, 'learning_rate': 2.1403431588209417e-05, 'epoch': 7.03}
{'loss': 0.0346, 'learning_rate': 2.030356357237132e-05, 'epoch': 7.18}
{'loss': 0.0386, 'learning_rate': 1.9203695556533217e-05, 'epoch': 7.33}
{'loss': 0.036, 'learning_rate': 1.8103827540695118e-05, 'epoch': 7.48}
{'loss': 0.0403, 'learning_rate': 1.700395952485702e-05, 'epoch': 7.64}
{'loss': 0.0462, 'learning_rate': 1.5904091509018918e-05, 'epoch': 7.79}
{'loss': 0.0382, 'learning_rate': 1.480422349318082e-05, 'epoch': 7.94}
{'eval_loss': 0.6667456030845642, 'eval_accuracy': 0.8755262676185246, 'eval_runtime': 166.5326, 'eval_samples_per_second': 32.804, 'eval_steps_per_second': 2.054, 'epoch': 8.0}
{'loss': 0.0321, 'learning_rate': 1.370435547734272e-05, 'epoch': 8.1}
{'loss': 0.0278, 'learning_rate': 1.260448746150462e-05, 'epoch': 8.25}
{'loss': 0.0264, 'learning_rate': 1.1504619445666521e-05, 'epoch': 8.4}
{'loss': 0.0233, 'learning_rate': 1.0404751429828421e-05, 'epoch': 8.55}
{'loss': 0.0328, 'learning_rate': 9.30488341399032e-06, 'epoch': 8.71}
{'loss': 0.0239, 'learning_rate': 8.205015398152222e-06, 'epoch': 8.86}
{'eval_loss': 0.735072672367096, 'eval_accuracy': 0.8735127219476478, 'eval_runtime': 165.616, 'eval_samples_per_second': 32.986, 'eval_steps_per_second': 2.065, 'epoch': 9.0}
{'loss': 0.0289, 'learning_rate': 7.105147382314123e-06, 'epoch': 9.01}
{'loss': 0.0189, 'learning_rate': 6.005279366476023e-06, 'epoch': 9.16}
{'loss': 0.0125, 'learning_rate': 4.905411350637924e-06, 'epoch': 9.32}
{'loss': 0.0191, 'learning_rate': 3.805543334799824e-06, 'epoch': 9.47}
{'loss': 0.0173, 'learning_rate': 2.7056753189617244e-06, 'epoch': 9.62}
{'loss': 0.0209, 'learning_rate': 1.6058073031236254e-06, 'epoch': 9.78}
{'loss': 0.0195, 'learning_rate': 5.059392872855257e-07, 'epoch': 9.93}
{'eval_loss': 0.7737066149711609, 'eval_accuracy': 0.8731466227347611, 'eval_runtime': 165.5835, 'eval_samples_per_second': 32.992, 'eval_steps_per_second': 2.065, 'epoch': 10.0}
{'train_runtime': 77249.1549, 'train_samples_per_second': 13.559, 'train_steps_per_second': 0.424, 'train_loss': 0.1738243899431354, 'epoch': 10.0}
Total training time: 77249.17 seconds
######################################################################
layer-wise fine-tuning top 3
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 201.50it/s]
/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.2', 'bert.encoder.layer.5', 'bert.encoder.layer.6', 'bert.encoder.layer.7', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
{'loss': 0.7376, 'learning_rate': 2.5e-06, 'epoch': 0.15}
{'loss': 0.538, 'learning_rate': 5e-06, 'epoch': 0.31}
{'loss': 0.4777, 'learning_rate': 7.5e-06, 'epoch': 0.46}
{'loss': 0.4396, 'learning_rate': 1e-05, 'epoch': 0.61}
{'loss': 0.4217, 'learning_rate': 1.25e-05, 'epoch': 0.76}
{'loss': 0.4063, 'learning_rate': 1.5e-05, 'epoch': 0.92}
{'eval_loss': 0.3324965536594391, 'eval_accuracy': 0.8594179022515102, 'eval_runtime': 165.0092, 'eval_samples_per_second': 33.107, 'eval_steps_per_second': 2.073, 'epoch': 1.0}
{'loss': 0.376, 'learning_rate': 1.75e-05, 'epoch': 1.07}
{'loss': 0.3554, 'learning_rate': 2e-05, 'epoch': 1.22}
{'loss': 0.3474, 'learning_rate': 2.25e-05, 'epoch': 1.37}
{'loss': 0.3452, 'learning_rate': 2.5e-05, 'epoch': 1.53}
{'loss': 0.3464, 'learning_rate': 2.7500000000000004e-05, 'epoch': 1.68}
{'loss': 0.336, 'learning_rate': 3e-05, 'epoch': 1.83}
{'loss': 0.3227, 'learning_rate': 3.2500000000000004e-05, 'epoch': 1.99}
{'eval_loss': 0.2908680737018585, 'eval_accuracy': 0.8808347062053816, 'eval_runtime': 165.1623, 'eval_samples_per_second': 33.077, 'eval_steps_per_second': 2.071, 'epoch': 2.0}
{'loss': 0.2577, 'learning_rate': 3.5e-05, 'epoch': 2.14}
{'loss': 0.2505, 'learning_rate': 3.7500000000000003e-05, 'epoch': 2.29}
{'loss': 0.2564, 'learning_rate': 4e-05, 'epoch': 2.44}
{'loss': 0.2613, 'learning_rate': 4.25e-05, 'epoch': 2.6}
{'loss': 0.2649, 'learning_rate': 4.5e-05, 'epoch': 2.75}
{'loss': 0.2722, 'learning_rate': 4.75e-05, 'epoch': 2.9}
{'eval_loss': 0.28907179832458496, 'eval_accuracy': 0.8868753432180121, 'eval_runtime': 165.0926, 'eval_samples_per_second': 33.091, 'eval_steps_per_second': 2.072, 'epoch': 3.0}
{'loss': 0.2286, 'learning_rate': 5e-05, 'epoch': 3.05}
{'loss': 0.1784, 'learning_rate': 4.8900131984161904e-05, 'epoch': 3.21}
{'loss': 0.1741, 'learning_rate': 4.7800263968323806e-05, 'epoch': 3.36}
{'loss': 0.1723, 'learning_rate': 4.67003959524857e-05, 'epoch': 3.51}
{'loss': 0.1798, 'learning_rate': 4.56005279366476e-05, 'epoch': 3.67}
{'loss': 0.1833, 'learning_rate': 4.4500659920809504e-05, 'epoch': 3.82}
{'loss': 0.1726, 'learning_rate': 4.3400791904971405e-05, 'epoch': 3.97}
{'eval_loss': 0.3359794616699219, 'eval_accuracy': 0.8850448471535787, 'eval_runtime': 165.0956, 'eval_samples_per_second': 33.09, 'eval_steps_per_second': 2.072, 'epoch': 4.0}
{'loss': 0.1113, 'learning_rate': 4.230092388913331e-05, 'epoch': 4.12}
{'loss': 0.0997, 'learning_rate': 4.120105587329521e-05, 'epoch': 4.28}
{'loss': 0.1052, 'learning_rate': 4.01011878574571e-05, 'epoch': 4.43}
{'loss': 0.1033, 'learning_rate': 3.9001319841619005e-05, 'epoch': 4.58}
{'loss': 0.1103, 'learning_rate': 3.7901451825780906e-05, 'epoch': 4.73}
{'loss': 0.1047, 'learning_rate': 3.680158380994281e-05, 'epoch': 4.89}
{'eval_loss': 0.43395212292671204, 'eval_accuracy': 0.8835804503020318, 'eval_runtime': 164.9985, 'eval_samples_per_second': 33.109, 'eval_steps_per_second': 2.073, 'epoch': 5.0}
{'loss': 0.0973, 'learning_rate': 3.570171579410471e-05, 'epoch': 5.04}
{'loss': 0.0616, 'learning_rate': 3.460184777826661e-05, 'epoch': 5.19}
{'loss': 0.0728, 'learning_rate': 3.3501979762428506e-05, 'epoch': 5.35}
{'loss': 0.0704, 'learning_rate': 3.2402111746590414e-05, 'epoch': 5.5}
{'loss': 0.0693, 'learning_rate': 3.130224373075231e-05, 'epoch': 5.65}
{'loss': 0.0744, 'learning_rate': 3.020237571491421e-05, 'epoch': 5.8}
{'loss': 0.0643, 'learning_rate': 2.9102507699076116e-05, 'epoch': 5.96}
{'eval_loss': 0.5613003969192505, 'eval_accuracy': 0.8832143510891451, 'eval_runtime': 165.1713, 'eval_samples_per_second': 33.075, 'eval_steps_per_second': 2.071, 'epoch': 6.0}
{'loss': 0.052, 'learning_rate': 2.8002639683238014e-05, 'epoch': 6.11}
{'loss': 0.0445, 'learning_rate': 2.6902771667399912e-05, 'epoch': 6.26}
{'loss': 0.0412, 'learning_rate': 2.5802903651561817e-05, 'epoch': 6.42}
{'loss': 0.0458, 'learning_rate': 2.4703035635723715e-05, 'epoch': 6.57}
{'loss': 0.0486, 'learning_rate': 2.3603167619885617e-05, 'epoch': 6.72}
{'loss': 0.0466, 'learning_rate': 2.2503299604047515e-05, 'epoch': 6.87}
{'eval_loss': 0.6235048770904541, 'eval_accuracy': 0.8848617975471352, 'eval_runtime': 165.1544, 'eval_samples_per_second': 33.078, 'eval_steps_per_second': 2.071, 'epoch': 7.0}
{'loss': 0.0449, 'learning_rate': 2.1403431588209417e-05, 'epoch': 7.03}
{'loss': 0.0263, 'learning_rate': 2.030356357237132e-05, 'epoch': 7.18}
{'loss': 0.0245, 'learning_rate': 1.9203695556533217e-05, 'epoch': 7.33}
{'loss': 0.0265, 'learning_rate': 1.8103827540695118e-05, 'epoch': 7.48}
{'loss': 0.0302, 'learning_rate': 1.700395952485702e-05, 'epoch': 7.64}
{'loss': 0.0293, 'learning_rate': 1.5904091509018918e-05, 'epoch': 7.79}
{'loss': 0.0337, 'learning_rate': 1.480422349318082e-05, 'epoch': 7.94}
{'eval_loss': 0.7213583588600159, 'eval_accuracy': 0.882116053450485, 'eval_runtime': 165.1971, 'eval_samples_per_second': 33.07, 'eval_steps_per_second': 2.07, 'epoch': 8.0}
{'loss': 0.0258, 'learning_rate': 1.370435547734272e-05, 'epoch': 8.1}
{'loss': 0.0198, 'learning_rate': 1.260448746150462e-05, 'epoch': 8.25}
{'loss': 0.0181, 'learning_rate': 1.1504619445666521e-05, 'epoch': 8.4}
{'loss': 0.0147, 'learning_rate': 1.0404751429828421e-05, 'epoch': 8.55}
{'loss': 0.0256, 'learning_rate': 9.30488341399032e-06, 'epoch': 8.71}
{'loss': 0.0152, 'learning_rate': 8.205015398152222e-06, 'epoch': 8.86}
{'eval_loss': 0.781080961227417, 'eval_accuracy': 0.8866922936115688, 'eval_runtime': 165.0315, 'eval_samples_per_second': 33.103, 'eval_steps_per_second': 2.072, 'epoch': 9.0}
{'loss': 0.0194, 'learning_rate': 7.105147382314123e-06, 'epoch': 9.01}
{'loss': 0.0101, 'learning_rate': 6.005279366476023e-06, 'epoch': 9.16}
{'loss': 0.0141, 'learning_rate': 4.905411350637924e-06, 'epoch': 9.32}
{'loss': 0.0124, 'learning_rate': 3.805543334799824e-06, 'epoch': 9.47}
{'loss': 0.013, 'learning_rate': 2.7056753189617244e-06, 'epoch': 9.62}
{'loss': 0.0142, 'learning_rate': 1.6058073031236254e-06, 'epoch': 9.78}
{'loss': 0.0114, 'learning_rate': 5.059392872855257e-07, 'epoch': 9.93}
{'eval_loss': 0.8155009150505066, 'eval_accuracy': 0.8865092440051254, 'eval_runtime': 165.2219, 'eval_samples_per_second': 33.065, 'eval_steps_per_second': 2.07, 'epoch': 10.0}
{'train_runtime': 78685.191, 'train_samples_per_second': 13.312, 'train_steps_per_second': 0.416, 'train_loss': 0.15523348894098865, 'epoch': 10.0}
Total training time: 78685.21 seconds
######################################################################
layer-wise fine-tuning top 4
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 316.67it/s]
Map:   0%|          | 0/10 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/10 [00:00<?, ? examples/s]                                                  /home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.2', 'bert.encoder.layer.6', 'bert.encoder.layer.7', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
Traceback (most recent call last):
  File "code/fine_tuner.py", line 148, in <module>
    main(args)
  File "code/fine_tuner.py", line 121, in main
    trainer.train()
  File "/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/trainer.py", line 1633, in train
    return inner_training_loop(
  File "/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/trainer.py", line 1994, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/trainer.py", line 2236, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/trainer.py", line 2932, in evaluate
    output = eval_loop(
  File "/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/trainer.py", line 3220, in evaluation_loop
    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))
TypeError: compute() takes 1 positional argument but 2 were given
######################################################################
layer-wise fine-tuning top 5
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 464.09it/s]
Map:   0%|          | 0/10 [00:00<?, ? examples/s]                                                  /home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('bert.encoder.layer.2', 'bert.encoder.layer.6', 'bert.encoder.layer.7', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
Traceback (most recent call last):
  File "code/fine_tuner.py", line 148, in <module>
    main(args)
  File "code/fine_tuner.py", line 121, in main
    trainer.train()
  File "/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/trainer.py", line 1633, in train
    return inner_training_loop(
  File "/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/trainer.py", line 1994, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/trainer.py", line 2236, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/trainer.py", line 2932, in evaluate
    output = eval_loop(
  File "/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/trainer.py", line 3220, in evaluation_loop
    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))
TypeError: compute() takes 1 positional argument but 2 were given
######################################################################
finished
