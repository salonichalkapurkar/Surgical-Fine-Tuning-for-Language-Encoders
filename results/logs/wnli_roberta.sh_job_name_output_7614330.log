######################################################################
full model fine-tuning
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 51.46it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
{'eval_loss': 0.7030139565467834, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3998, 'eval_samples_per_second': 29.585, 'eval_steps_per_second': 2.083, 'epoch': 1.0}
{'eval_loss': 0.702833890914917, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3516, 'eval_samples_per_second': 30.192, 'eval_steps_per_second': 2.126, 'epoch': 2.0}
{'eval_loss': 0.702491283416748, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3597, 'eval_samples_per_second': 30.088, 'eval_steps_per_second': 2.119, 'epoch': 3.0}
{'eval_loss': 0.7020042538642883, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.364, 'eval_samples_per_second': 30.033, 'eval_steps_per_second': 2.115, 'epoch': 4.0}
{'eval_loss': 0.7011725902557373, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3491, 'eval_samples_per_second': 30.224, 'eval_steps_per_second': 2.128, 'epoch': 5.0}
{'eval_loss': 0.7007107138633728, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3608, 'eval_samples_per_second': 30.075, 'eval_steps_per_second': 2.118, 'epoch': 6.0}
{'eval_loss': 0.6998053789138794, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3525, 'eval_samples_per_second': 30.181, 'eval_steps_per_second': 2.125, 'epoch': 7.0}
{'eval_loss': 0.6993002891540527, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3511, 'eval_samples_per_second': 30.198, 'eval_steps_per_second': 2.127, 'epoch': 8.0}
{'eval_loss': 0.6982351541519165, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3589, 'eval_samples_per_second': 30.099, 'eval_steps_per_second': 2.12, 'epoch': 9.0}
{'eval_loss': 0.6975778341293335, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3568, 'eval_samples_per_second': 30.126, 'eval_steps_per_second': 2.122, 'epoch': 10.0}
{'train_runtime': 756.2065, 'train_samples_per_second': 8.397, 'train_steps_per_second': 0.264, 'train_loss': 0.6962336730957032, 'epoch': 10.0}
Total training time: 756.23 seconds
######################################################################
layer-wise fine-tuning top 1
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 209.81it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.2', 'roberta.encoder.layer.3', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6', 'roberta.encoder.layer.7', 'roberta.encoder.layer.8', 'roberta.encoder.layer.9', 'roberta.encoder.layer.10')
{'eval_loss': 0.7031022906303406, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3459, 'eval_samples_per_second': 30.266, 'eval_steps_per_second': 2.131, 'epoch': 1.0}
{'eval_loss': 0.7030442953109741, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3192, 'eval_samples_per_second': 30.614, 'eval_steps_per_second': 2.156, 'epoch': 2.0}
{'eval_loss': 0.7029326558113098, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3275, 'eval_samples_per_second': 30.505, 'eval_steps_per_second': 2.148, 'epoch': 3.0}
{'eval_loss': 0.7027595639228821, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3217, 'eval_samples_per_second': 30.581, 'eval_steps_per_second': 2.154, 'epoch': 4.0}
{'eval_loss': 0.702511191368103, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3398, 'eval_samples_per_second': 30.345, 'eval_steps_per_second': 2.137, 'epoch': 5.0}
{'eval_loss': 0.7023142576217651, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3282, 'eval_samples_per_second': 30.496, 'eval_steps_per_second': 2.148, 'epoch': 6.0}
{'eval_loss': 0.7020349502563477, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3232, 'eval_samples_per_second': 30.561, 'eval_steps_per_second': 2.152, 'epoch': 7.0}
{'eval_loss': 0.7018402814865112, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3257, 'eval_samples_per_second': 30.528, 'eval_steps_per_second': 2.15, 'epoch': 8.0}
{'eval_loss': 0.7014521956443787, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3293, 'eval_samples_per_second': 30.482, 'eval_steps_per_second': 2.147, 'epoch': 9.0}
{'eval_loss': 0.7011217474937439, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3239, 'eval_samples_per_second': 30.552, 'eval_steps_per_second': 2.152, 'epoch': 10.0}
{'train_runtime': 557.0794, 'train_samples_per_second': 11.399, 'train_steps_per_second': 0.359, 'train_loss': 0.6967536163330078, 'epoch': 10.0}
Total training time: 557.10 seconds
######################################################################
layer-wise fine-tuning top 2
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 222.49it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.2', 'roberta.encoder.layer.3', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6', 'roberta.encoder.layer.7', 'roberta.encoder.layer.8', 'roberta.encoder.layer.9')
{'eval_loss': 0.7031022906303406, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3447, 'eval_samples_per_second': 30.281, 'eval_steps_per_second': 2.132, 'epoch': 1.0}
{'eval_loss': 0.7030442953109741, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3169, 'eval_samples_per_second': 30.644, 'eval_steps_per_second': 2.158, 'epoch': 2.0}
{'eval_loss': 0.7029326558113098, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3247, 'eval_samples_per_second': 30.542, 'eval_steps_per_second': 2.151, 'epoch': 3.0}
{'eval_loss': 0.7027595639228821, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3241, 'eval_samples_per_second': 30.55, 'eval_steps_per_second': 2.151, 'epoch': 4.0}
{'eval_loss': 0.702511191368103, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3209, 'eval_samples_per_second': 30.591, 'eval_steps_per_second': 2.154, 'epoch': 5.0}
{'eval_loss': 0.7023142576217651, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3216, 'eval_samples_per_second': 30.582, 'eval_steps_per_second': 2.154, 'epoch': 6.0}
{'eval_loss': 0.7020349502563477, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3296, 'eval_samples_per_second': 30.477, 'eval_steps_per_second': 2.146, 'epoch': 7.0}
{'eval_loss': 0.7018402814865112, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3281, 'eval_samples_per_second': 30.498, 'eval_steps_per_second': 2.148, 'epoch': 8.0}
{'eval_loss': 0.7014521956443787, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.321, 'eval_samples_per_second': 30.591, 'eval_steps_per_second': 2.154, 'epoch': 9.0}
{'eval_loss': 0.7011217474937439, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3201, 'eval_samples_per_second': 30.602, 'eval_steps_per_second': 2.155, 'epoch': 10.0}
{'train_runtime': 556.893, 'train_samples_per_second': 11.403, 'train_steps_per_second': 0.359, 'train_loss': 0.6967536163330078, 'epoch': 10.0}
Total training time: 556.91 seconds
######################################################################
layer-wise fine-tuning top 3
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 220.28it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.2', 'roberta.encoder.layer.3', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6', 'roberta.encoder.layer.7', 'roberta.encoder.layer.8')
{'eval_loss': 0.7030954360961914, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3334, 'eval_samples_per_second': 30.427, 'eval_steps_per_second': 2.143, 'epoch': 1.0}
{'eval_loss': 0.7030318379402161, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3273, 'eval_samples_per_second': 30.507, 'eval_steps_per_second': 2.148, 'epoch': 2.0}
{'eval_loss': 0.702904999256134, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3253, 'eval_samples_per_second': 30.533, 'eval_steps_per_second': 2.15, 'epoch': 3.0}
{'eval_loss': 0.7027063965797424, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3258, 'eval_samples_per_second': 30.527, 'eval_steps_per_second': 2.15, 'epoch': 4.0}
{'eval_loss': 0.7024045586585999, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3166, 'eval_samples_per_second': 30.649, 'eval_steps_per_second': 2.158, 'epoch': 5.0}
{'eval_loss': 0.7021842002868652, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3217, 'eval_samples_per_second': 30.581, 'eval_steps_per_second': 2.154, 'epoch': 6.0}
{'eval_loss': 0.7018567323684692, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3397, 'eval_samples_per_second': 30.345, 'eval_steps_per_second': 2.137, 'epoch': 7.0}
{'eval_loss': 0.7016358375549316, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3211, 'eval_samples_per_second': 30.589, 'eval_steps_per_second': 2.154, 'epoch': 8.0}
{'eval_loss': 0.7011864185333252, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3214, 'eval_samples_per_second': 30.585, 'eval_steps_per_second': 2.154, 'epoch': 9.0}
{'eval_loss': 0.7008178234100342, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3251, 'eval_samples_per_second': 30.536, 'eval_steps_per_second': 2.15, 'epoch': 10.0}
{'train_runtime': 573.4357, 'train_samples_per_second': 11.074, 'train_steps_per_second': 0.349, 'train_loss': 0.6967079162597656, 'epoch': 10.0}
Total training time: 573.45 seconds
######################################################################
layer-wise fine-tuning top 4
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 217.54it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.2', 'roberta.encoder.layer.3', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6', 'roberta.encoder.layer.7')
{'eval_loss': 0.7030905485153198, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3554, 'eval_samples_per_second': 30.144, 'eval_steps_per_second': 2.123, 'epoch': 1.0}
{'eval_loss': 0.7030234932899475, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3284, 'eval_samples_per_second': 30.494, 'eval_steps_per_second': 2.147, 'epoch': 2.0}
{'eval_loss': 0.7028850317001343, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3366, 'eval_samples_per_second': 30.386, 'eval_steps_per_second': 2.14, 'epoch': 3.0}
{'eval_loss': 0.702667236328125, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3356, 'eval_samples_per_second': 30.399, 'eval_steps_per_second': 2.141, 'epoch': 4.0}
{'eval_loss': 0.7023283243179321, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.323, 'eval_samples_per_second': 30.564, 'eval_steps_per_second': 2.152, 'epoch': 5.0}
{'eval_loss': 0.7020923495292664, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3295, 'eval_samples_per_second': 30.479, 'eval_steps_per_second': 2.146, 'epoch': 6.0}
{'eval_loss': 0.7017279267311096, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3303, 'eval_samples_per_second': 30.468, 'eval_steps_per_second': 2.146, 'epoch': 7.0}
{'eval_loss': 0.7014877200126648, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3332, 'eval_samples_per_second': 30.43, 'eval_steps_per_second': 2.143, 'epoch': 8.0}
{'eval_loss': 0.700999915599823, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3334, 'eval_samples_per_second': 30.428, 'eval_steps_per_second': 2.143, 'epoch': 9.0}
{'eval_loss': 0.7006091475486755, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3309, 'eval_samples_per_second': 30.46, 'eval_steps_per_second': 2.145, 'epoch': 10.0}
{'train_runtime': 589.4444, 'train_samples_per_second': 10.773, 'train_steps_per_second': 0.339, 'train_loss': 0.696673583984375, 'epoch': 10.0}
Total training time: 589.46 seconds
######################################################################
layer-wise fine-tuning top 5
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 189.61it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.2', 'roberta.encoder.layer.3', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6')
{'eval_loss': 0.7030870914459229, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.343, 'eval_samples_per_second': 30.303, 'eval_steps_per_second': 2.134, 'epoch': 1.0}
{'eval_loss': 0.7030171751976013, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3261, 'eval_samples_per_second': 30.523, 'eval_steps_per_second': 2.149, 'epoch': 2.0}
{'eval_loss': 0.7028694152832031, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3398, 'eval_samples_per_second': 30.345, 'eval_steps_per_second': 2.137, 'epoch': 3.0}
{'eval_loss': 0.7026351094245911, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3315, 'eval_samples_per_second': 30.453, 'eval_steps_per_second': 2.145, 'epoch': 4.0}
{'eval_loss': 0.7022662162780762, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.332, 'eval_samples_per_second': 30.446, 'eval_steps_per_second': 2.144, 'epoch': 5.0}
{'eval_loss': 0.7020204067230225, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.336, 'eval_samples_per_second': 30.394, 'eval_steps_per_second': 2.14, 'epoch': 6.0}
{'eval_loss': 0.7016258835792542, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3298, 'eval_samples_per_second': 30.474, 'eval_steps_per_second': 2.146, 'epoch': 7.0}
{'eval_loss': 0.7013712525367737, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3306, 'eval_samples_per_second': 30.465, 'eval_steps_per_second': 2.145, 'epoch': 8.0}
{'eval_loss': 0.7008549571037292, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3292, 'eval_samples_per_second': 30.482, 'eval_steps_per_second': 2.147, 'epoch': 9.0}
{'eval_loss': 0.7004494071006775, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3304, 'eval_samples_per_second': 30.467, 'eval_steps_per_second': 2.146, 'epoch': 10.0}
{'train_runtime': 605.4322, 'train_samples_per_second': 10.488, 'train_steps_per_second': 0.33, 'train_loss': 0.696647720336914, 'epoch': 10.0}
Total training time: 605.45 seconds
######################################################################
finished
