######################################################################
full model fine-tuning
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
Downloading builder script:   0%|          | 0.00/5.30k [00:00<?, ?B/s]Downloading builder script: 100%|██████████| 5.30k/5.30k [00:00<00:00, 8.57MB/s]
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:00,  9.96it/s]100%|██████████| 3/3 [00:00<00:00, 23.90it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.
  warnings.warn(stats.ConstantInputWarning(msg))
{'eval_loss': 3.1661012172698975, 'eval_pearsonr': nan, 'eval_runtime': 54.0703, 'eval_samples_per_second': 27.742, 'eval_steps_per_second': 3.477, 'epoch': 1.0}
{'loss': 4.4041, 'learning_rate': 2.5e-06, 'epoch': 1.39}
{'eval_loss': 0.6740052700042725, 'eval_pearsonr': nan, 'eval_runtime': 53.8607, 'eval_samples_per_second': 27.85, 'eval_steps_per_second': 3.49, 'epoch': 2.0}
{'loss': 0.7535, 'learning_rate': 5e-06, 'epoch': 2.78}
{'eval_loss': 0.589287519454956, 'eval_pearsonr': nan, 'eval_runtime': 53.8513, 'eval_samples_per_second': 27.854, 'eval_steps_per_second': 3.491, 'epoch': 3.0}
{'eval_loss': 0.627828061580658, 'eval_pearsonr': nan, 'eval_runtime': 53.8372, 'eval_samples_per_second': 27.862, 'eval_steps_per_second': 3.492, 'epoch': 4.0}
{'loss': 0.4963, 'learning_rate': 7.5e-06, 'epoch': 4.17}
{'eval_loss': 0.4673771262168884, 'eval_pearsonr': nan, 'eval_runtime': 53.847, 'eval_samples_per_second': 27.857, 'eval_steps_per_second': 3.491, 'epoch': 5.0}
{'loss': 0.3246, 'learning_rate': 1e-05, 'epoch': 5.56}
{'eval_loss': 0.47118425369262695, 'eval_pearsonr': nan, 'eval_runtime': 53.8136, 'eval_samples_per_second': 27.874, 'eval_steps_per_second': 3.494, 'epoch': 6.0}
{'loss': 0.2271, 'learning_rate': 1.25e-05, 'epoch': 6.95}
{'eval_loss': 0.5003071427345276, 'eval_pearsonr': nan, 'eval_runtime': 53.877, 'eval_samples_per_second': 27.841, 'eval_steps_per_second': 3.489, 'epoch': 7.0}
{'eval_loss': 0.47661709785461426, 'eval_pearsonr': nan, 'eval_runtime': 53.8173, 'eval_samples_per_second': 27.872, 'eval_steps_per_second': 3.493, 'epoch': 8.0}
{'loss': 0.1612, 'learning_rate': 1.5e-05, 'epoch': 8.34}
{'eval_loss': 0.4796113967895508, 'eval_pearsonr': nan, 'eval_runtime': 53.8739, 'eval_samples_per_second': 27.843, 'eval_steps_per_second': 3.49, 'epoch': 9.0}
{'loss': 0.1404, 'learning_rate': 1.75e-05, 'epoch': 9.74}
{'eval_loss': 0.48669376969337463, 'eval_pearsonr': nan, 'eval_runtime': 53.853, 'eval_samples_per_second': 27.854, 'eval_steps_per_second': 3.491, 'epoch': 9.99}
{'train_runtime': 6084.8158, 'train_samples_per_second': 9.448, 'train_steps_per_second': 0.59, 'train_loss': 0.9093450110602844, 'epoch': 9.99}
Total training time: 6084.85 seconds
######################################################################
layer-wise fine-tuning top 1
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 411.14it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.
  warnings.warn(stats.ConstantInputWarning(msg))
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.1', 'bert.encoder.layer.2', 'bert.encoder.layer.3', 'bert.encoder.layer.4', 'bert.encoder.layer.6', 'bert.encoder.layer.7', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
{'eval_loss': 3.8619022369384766, 'eval_pearsonr': nan, 'eval_runtime': 53.798, 'eval_samples_per_second': 27.882, 'eval_steps_per_second': 3.495, 'epoch': 1.0}
{'loss': 5.3295, 'learning_rate': 2.5e-06, 'epoch': 1.39}
{'eval_loss': 1.8209222555160522, 'eval_pearsonr': nan, 'eval_runtime': 53.8006, 'eval_samples_per_second': 27.881, 'eval_steps_per_second': 3.494, 'epoch': 2.0}
{'loss': 2.1663, 'learning_rate': 5e-06, 'epoch': 2.78}
{'eval_loss': 0.919974684715271, 'eval_pearsonr': nan, 'eval_runtime': 53.7711, 'eval_samples_per_second': 27.896, 'eval_steps_per_second': 3.496, 'epoch': 3.0}
{'eval_loss': 0.7458701133728027, 'eval_pearsonr': nan, 'eval_runtime': 53.7843, 'eval_samples_per_second': 27.889, 'eval_steps_per_second': 3.495, 'epoch': 4.0}
{'loss': 0.9568, 'learning_rate': 7.5e-06, 'epoch': 4.17}
{'eval_loss': 0.6588722467422485, 'eval_pearsonr': nan, 'eval_runtime': 53.7869, 'eval_samples_per_second': 27.888, 'eval_steps_per_second': 3.495, 'epoch': 5.0}
{'loss': 0.745, 'learning_rate': 1e-05, 'epoch': 5.56}
{'eval_loss': 0.6037446856498718, 'eval_pearsonr': nan, 'eval_runtime': 53.7605, 'eval_samples_per_second': 27.902, 'eval_steps_per_second': 3.497, 'epoch': 6.0}
{'loss': 0.5941, 'learning_rate': 1.25e-05, 'epoch': 6.95}
{'eval_loss': 0.5895807147026062, 'eval_pearsonr': nan, 'eval_runtime': 53.7705, 'eval_samples_per_second': 27.896, 'eval_steps_per_second': 3.496, 'epoch': 7.0}
{'eval_loss': 0.5714678764343262, 'eval_pearsonr': nan, 'eval_runtime': 53.7689, 'eval_samples_per_second': 27.897, 'eval_steps_per_second': 3.496, 'epoch': 8.0}
{'loss': 0.4614, 'learning_rate': 1.5e-05, 'epoch': 8.34}
{'eval_loss': 0.5584475994110107, 'eval_pearsonr': nan, 'eval_runtime': 55.1239, 'eval_samples_per_second': 27.211, 'eval_steps_per_second': 3.411, 'epoch': 9.0}
{'loss': 0.3772, 'learning_rate': 1.75e-05, 'epoch': 9.74}
{'eval_loss': 0.5697927474975586, 'eval_pearsonr': nan, 'eval_runtime': 55.7046, 'eval_samples_per_second': 26.928, 'eval_steps_per_second': 3.375, 'epoch': 9.99}
{'train_runtime': 4883.3092, 'train_samples_per_second': 11.773, 'train_steps_per_second': 0.735, 'train_loss': 1.4891382812457497, 'epoch': 9.99}
Total training time: 4883.32 seconds
######################################################################
layer-wise fine-tuning top 2
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 482.40it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.
  warnings.warn(stats.ConstantInputWarning(msg))
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.2', 'bert.encoder.layer.3', 'bert.encoder.layer.4', 'bert.encoder.layer.6', 'bert.encoder.layer.7', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
{'eval_loss': 3.855280637741089, 'eval_pearsonr': nan, 'eval_runtime': 55.96, 'eval_samples_per_second': 26.805, 'eval_steps_per_second': 3.36, 'epoch': 1.0}
{'loss': 5.3215, 'learning_rate': 2.5e-06, 'epoch': 1.39}
{'eval_loss': 1.8052700757980347, 'eval_pearsonr': nan, 'eval_runtime': 55.8522, 'eval_samples_per_second': 26.857, 'eval_steps_per_second': 3.366, 'epoch': 2.0}
{'loss': 2.1418, 'learning_rate': 5e-06, 'epoch': 2.78}
{'eval_loss': 0.8970844745635986, 'eval_pearsonr': nan, 'eval_runtime': 55.6597, 'eval_samples_per_second': 26.949, 'eval_steps_per_second': 3.378, 'epoch': 3.0}
{'eval_loss': 0.6973071098327637, 'eval_pearsonr': nan, 'eval_runtime': 55.6108, 'eval_samples_per_second': 26.973, 'eval_steps_per_second': 3.381, 'epoch': 4.0}
{'loss': 0.8987, 'learning_rate': 7.5e-06, 'epoch': 4.17}
{'eval_loss': 0.6249801516532898, 'eval_pearsonr': nan, 'eval_runtime': 55.8407, 'eval_samples_per_second': 26.862, 'eval_steps_per_second': 3.367, 'epoch': 5.0}
{'loss': 0.6676, 'learning_rate': 1e-05, 'epoch': 5.56}
{'eval_loss': 0.5904811024665833, 'eval_pearsonr': nan, 'eval_runtime': 55.8155, 'eval_samples_per_second': 26.874, 'eval_steps_per_second': 3.368, 'epoch': 6.0}
{'loss': 0.5163, 'learning_rate': 1.25e-05, 'epoch': 6.95}
{'eval_loss': 0.5707074403762817, 'eval_pearsonr': nan, 'eval_runtime': 55.9758, 'eval_samples_per_second': 26.797, 'eval_steps_per_second': 3.359, 'epoch': 7.0}
{'eval_loss': 0.5685792565345764, 'eval_pearsonr': nan, 'eval_runtime': 55.4904, 'eval_samples_per_second': 27.032, 'eval_steps_per_second': 3.388, 'epoch': 8.0}
{'loss': 0.3792, 'learning_rate': 1.5e-05, 'epoch': 8.34}
{'eval_loss': 0.563836932182312, 'eval_pearsonr': nan, 'eval_runtime': 55.6845, 'eval_samples_per_second': 26.937, 'eval_steps_per_second': 3.376, 'epoch': 9.0}
{'loss': 0.2986, 'learning_rate': 1.75e-05, 'epoch': 9.74}
{'eval_loss': 0.5633239150047302, 'eval_pearsonr': nan, 'eval_runtime': 55.9468, 'eval_samples_per_second': 26.811, 'eval_steps_per_second': 3.36, 'epoch': 9.99}
{'train_runtime': 5110.8493, 'train_samples_per_second': 11.249, 'train_steps_per_second': 0.702, 'train_loss': 1.430503986007988, 'epoch': 9.99}
Total training time: 5110.87 seconds
######################################################################
layer-wise fine-tuning top 3
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 376.98it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.
  warnings.warn(stats.ConstantInputWarning(msg))
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.2', 'bert.encoder.layer.3', 'bert.encoder.layer.6', 'bert.encoder.layer.7', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
{'eval_loss': 3.833824634552002, 'eval_pearsonr': nan, 'eval_runtime': 56.0186, 'eval_samples_per_second': 26.777, 'eval_steps_per_second': 3.356, 'epoch': 1.0}
{'loss': 5.3007, 'learning_rate': 2.5e-06, 'epoch': 1.39}
{'eval_loss': 1.7819161415100098, 'eval_pearsonr': nan, 'eval_runtime': 56.1238, 'eval_samples_per_second': 26.727, 'eval_steps_per_second': 3.35, 'epoch': 2.0}
{'loss': 2.0945, 'learning_rate': 5e-06, 'epoch': 2.78}
{'eval_loss': 0.7427722215652466, 'eval_pearsonr': nan, 'eval_runtime': 55.9641, 'eval_samples_per_second': 26.803, 'eval_steps_per_second': 3.359, 'epoch': 3.0}
{'eval_loss': 0.6031172871589661, 'eval_pearsonr': nan, 'eval_runtime': 55.9713, 'eval_samples_per_second': 26.799, 'eval_steps_per_second': 3.359, 'epoch': 4.0}
{'loss': 0.7747, 'learning_rate': 7.5e-06, 'epoch': 4.17}
{'eval_loss': 0.5570763349533081, 'eval_pearsonr': nan, 'eval_runtime': 56.0739, 'eval_samples_per_second': 26.75, 'eval_steps_per_second': 3.353, 'epoch': 5.0}
{'loss': 0.5463, 'learning_rate': 1e-05, 'epoch': 5.56}
{'eval_loss': 0.555627703666687, 'eval_pearsonr': nan, 'eval_runtime': 55.9764, 'eval_samples_per_second': 26.797, 'eval_steps_per_second': 3.359, 'epoch': 6.0}
{'loss': 0.413, 'learning_rate': 1.25e-05, 'epoch': 6.95}
{'eval_loss': 0.5348935723304749, 'eval_pearsonr': nan, 'eval_runtime': 56.0344, 'eval_samples_per_second': 26.769, 'eval_steps_per_second': 3.355, 'epoch': 7.0}
{'eval_loss': 0.5552850961685181, 'eval_pearsonr': nan, 'eval_runtime': 55.9819, 'eval_samples_per_second': 26.794, 'eval_steps_per_second': 3.358, 'epoch': 8.0}
{'loss': 0.2987, 'learning_rate': 1.5e-05, 'epoch': 8.34}
{'eval_loss': 0.5585810542106628, 'eval_pearsonr': nan, 'eval_runtime': 55.7213, 'eval_samples_per_second': 26.92, 'eval_steps_per_second': 3.374, 'epoch': 9.0}
{'loss': 0.2323, 'learning_rate': 1.75e-05, 'epoch': 9.74}
{'eval_loss': 0.5304022431373596, 'eval_pearsonr': nan, 'eval_runtime': 56.0365, 'eval_samples_per_second': 26.768, 'eval_steps_per_second': 3.355, 'epoch': 9.99}
{'train_runtime': 5244.1683, 'train_samples_per_second': 10.963, 'train_steps_per_second': 0.685, 'train_loss': 1.3503720705887734, 'epoch': 9.99}
Total training time: 5244.18 seconds
######################################################################
layer-wise fine-tuning top 4
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 460.76it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.
  warnings.warn(stats.ConstantInputWarning(msg))
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.2', 'bert.encoder.layer.6', 'bert.encoder.layer.7', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
{'eval_loss': 3.8200502395629883, 'eval_pearsonr': nan, 'eval_runtime': 55.842, 'eval_samples_per_second': 26.862, 'eval_steps_per_second': 3.367, 'epoch': 1.0}
{'loss': 5.2868, 'learning_rate': 2.5e-06, 'epoch': 1.39}
{'eval_loss': 1.7503536939620972, 'eval_pearsonr': nan, 'eval_runtime': 55.7358, 'eval_samples_per_second': 26.913, 'eval_steps_per_second': 3.373, 'epoch': 2.0}
{'loss': 2.0032, 'learning_rate': 5e-06, 'epoch': 2.78}
{'eval_loss': 0.626040518283844, 'eval_pearsonr': nan, 'eval_runtime': 55.797, 'eval_samples_per_second': 26.883, 'eval_steps_per_second': 3.369, 'epoch': 3.0}
{'eval_loss': 0.5762860774993896, 'eval_pearsonr': nan, 'eval_runtime': 55.9454, 'eval_samples_per_second': 26.812, 'eval_steps_per_second': 3.36, 'epoch': 4.0}
{'loss': 0.6916, 'learning_rate': 7.5e-06, 'epoch': 4.17}
{'eval_loss': 0.5219480991363525, 'eval_pearsonr': nan, 'eval_runtime': 55.943, 'eval_samples_per_second': 26.813, 'eval_steps_per_second': 3.361, 'epoch': 5.0}
{'loss': 0.4932, 'learning_rate': 1e-05, 'epoch': 5.56}
{'eval_loss': 0.518719494342804, 'eval_pearsonr': nan, 'eval_runtime': 55.6807, 'eval_samples_per_second': 26.939, 'eval_steps_per_second': 3.376, 'epoch': 6.0}
{'loss': 0.369, 'learning_rate': 1.25e-05, 'epoch': 6.95}
{'eval_loss': 0.5169006586074829, 'eval_pearsonr': nan, 'eval_runtime': 55.6941, 'eval_samples_per_second': 26.933, 'eval_steps_per_second': 3.376, 'epoch': 7.0}
{'eval_loss': 0.5454881191253662, 'eval_pearsonr': nan, 'eval_runtime': 55.6767, 'eval_samples_per_second': 26.941, 'eval_steps_per_second': 3.377, 'epoch': 8.0}
{'loss': 0.275, 'learning_rate': 1.5e-05, 'epoch': 8.34}
{'eval_loss': 0.5121510624885559, 'eval_pearsonr': nan, 'eval_runtime': 55.6304, 'eval_samples_per_second': 26.964, 'eval_steps_per_second': 3.379, 'epoch': 9.0}
{'loss': 0.214, 'learning_rate': 1.75e-05, 'epoch': 9.74}
{'eval_loss': 0.516548752784729, 'eval_pearsonr': nan, 'eval_runtime': 55.7652, 'eval_samples_per_second': 26.898, 'eval_steps_per_second': 3.371, 'epoch': 9.99}
{'train_runtime': 5344.1933, 'train_samples_per_second': 10.757, 'train_steps_per_second': 0.672, 'train_loss': 1.304433749313142, 'epoch': 9.99}
Total training time: 5344.22 seconds
######################################################################
layer-wise fine-tuning top 5
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 354.92it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.
  warnings.warn(stats.ConstantInputWarning(msg))
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.6', 'bert.encoder.layer.7', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
{'eval_loss': 3.810004472732544, 'eval_pearsonr': nan, 'eval_runtime': 55.7836, 'eval_samples_per_second': 26.89, 'eval_steps_per_second': 3.37, 'epoch': 1.0}
{'loss': 5.2779, 'learning_rate': 2.5e-06, 'epoch': 1.39}
{'eval_loss': 1.5413442850112915, 'eval_pearsonr': nan, 'eval_runtime': 55.9025, 'eval_samples_per_second': 26.832, 'eval_steps_per_second': 3.363, 'epoch': 2.0}
{'loss': 1.8719, 'learning_rate': 5e-06, 'epoch': 2.78}
{'eval_loss': 0.6405481100082397, 'eval_pearsonr': nan, 'eval_runtime': 55.7506, 'eval_samples_per_second': 26.906, 'eval_steps_per_second': 3.372, 'epoch': 3.0}
{'eval_loss': 0.6285267472267151, 'eval_pearsonr': nan, 'eval_runtime': 55.6669, 'eval_samples_per_second': 26.946, 'eval_steps_per_second': 3.377, 'epoch': 4.0}
{'loss': 0.6752, 'learning_rate': 7.5e-06, 'epoch': 4.17}
{'eval_loss': 0.6299600005149841, 'eval_pearsonr': nan, 'eval_runtime': 55.7723, 'eval_samples_per_second': 26.895, 'eval_steps_per_second': 3.371, 'epoch': 5.0}
{'loss': 0.4762, 'learning_rate': 1e-05, 'epoch': 5.56}
{'eval_loss': 0.5518088936805725, 'eval_pearsonr': nan, 'eval_runtime': 55.8853, 'eval_samples_per_second': 26.841, 'eval_steps_per_second': 3.364, 'epoch': 6.0}
{'loss': 0.3541, 'learning_rate': 1.25e-05, 'epoch': 6.95}
{'eval_loss': 0.5810202360153198, 'eval_pearsonr': nan, 'eval_runtime': 55.8553, 'eval_samples_per_second': 26.855, 'eval_steps_per_second': 3.366, 'epoch': 7.0}
{'eval_loss': 0.5988354682922363, 'eval_pearsonr': nan, 'eval_runtime': 53.7655, 'eval_samples_per_second': 27.899, 'eval_steps_per_second': 3.497, 'epoch': 8.0}
{'loss': 0.2593, 'learning_rate': 1.5e-05, 'epoch': 8.34}
{'eval_loss': 0.5693926811218262, 'eval_pearsonr': nan, 'eval_runtime': 53.7808, 'eval_samples_per_second': 27.891, 'eval_steps_per_second': 3.496, 'epoch': 9.0}
{'loss': 0.2, 'learning_rate': 1.75e-05, 'epoch': 9.74}
{'eval_loss': 0.5610345005989075, 'eval_pearsonr': nan, 'eval_runtime': 53.7499, 'eval_samples_per_second': 27.907, 'eval_steps_per_second': 3.498, 'epoch': 9.99}
{'train_runtime': 5421.2556, 'train_samples_per_second': 10.605, 'train_steps_per_second': 0.662, 'train_loss': 1.2740547775226052, 'epoch': 9.99}
Total training time: 5421.27 seconds
######################################################################
finished
