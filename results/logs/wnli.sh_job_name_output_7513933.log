######################################################################
layer-wise fine-tuning bottom 1
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 49.73it/s]
/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.1', 'bert.encoder.layer.2', 'bert.encoder.layer.3', 'bert.encoder.layer.4', 'bert.encoder.layer.5', 'bert.encoder.layer.6', 'bert.encoder.layer.7', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
{'eval_loss': 0.8020941019058228, 'eval_accuracy': 0.5633802816901409, 'eval_runtime': 2.2693, 'eval_samples_per_second': 31.287, 'eval_steps_per_second': 2.203, 'epoch': 1.0}
{'eval_loss': 0.8005813360214233, 'eval_accuracy': 0.5633802816901409, 'eval_runtime': 2.3253, 'eval_samples_per_second': 30.534, 'eval_steps_per_second': 2.15, 'epoch': 2.0}
{'eval_loss': 0.7980815172195435, 'eval_accuracy': 0.5633802816901409, 'eval_runtime': 2.3753, 'eval_samples_per_second': 29.891, 'eval_steps_per_second': 2.105, 'epoch': 3.0}
{'eval_loss': 0.7945544123649597, 'eval_accuracy': 0.5633802816901409, 'eval_runtime': 2.3137, 'eval_samples_per_second': 30.686, 'eval_steps_per_second': 2.161, 'epoch': 4.0}
{'eval_loss': 0.7900496125221252, 'eval_accuracy': 0.5633802816901409, 'eval_runtime': 2.311, 'eval_samples_per_second': 30.722, 'eval_steps_per_second': 2.164, 'epoch': 5.0}
{'eval_loss': 0.7846731543540955, 'eval_accuracy': 0.5633802816901409, 'eval_runtime': 2.3153, 'eval_samples_per_second': 30.666, 'eval_steps_per_second': 2.16, 'epoch': 6.0}
{'eval_loss': 0.7781380414962769, 'eval_accuracy': 0.5633802816901409, 'eval_runtime': 2.302, 'eval_samples_per_second': 30.843, 'eval_steps_per_second': 2.172, 'epoch': 7.0}
{'eval_loss': 0.770375669002533, 'eval_accuracy': 0.5633802816901409, 'eval_runtime': 2.2932, 'eval_samples_per_second': 30.96, 'eval_steps_per_second': 2.18, 'epoch': 8.0}
{'eval_loss': 0.7612332701683044, 'eval_accuracy': 0.5633802816901409, 'eval_runtime': 2.2945, 'eval_samples_per_second': 30.944, 'eval_steps_per_second': 2.179, 'epoch': 9.0}
{'eval_loss': 0.7499824166297913, 'eval_accuracy': 0.5633802816901409, 'eval_runtime': 2.3018, 'eval_samples_per_second': 30.845, 'eval_steps_per_second': 2.172, 'epoch': 10.0}
{'train_runtime': 550.0325, 'train_samples_per_second': 11.545, 'train_steps_per_second': 0.364, 'train_loss': 0.8583315277099609, 'epoch': 10.0}
Total training time: 550.06 seconds
