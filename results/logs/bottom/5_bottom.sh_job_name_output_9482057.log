######################################################################
layer-wise fine-tuning freezing bottom 5 BOOLQ
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:00,  7.47it/s]100%|██████████| 3/3 [00:00<00:00, 13.72it/s]
/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.1', 'bert.encoder.layer.2', 'bert.encoder.layer.3', 'bert.encoder.layer.4')
{'eval_loss': 0.6658356785774231, 'eval_accuracy': 0.6131498470948012, 'eval_runtime': 104.5132, 'eval_samples_per_second': 31.288, 'eval_steps_per_second': 1.961, 'epoch': 1.0}
{'loss': 0.7767, 'learning_rate': 2.5e-06, 'epoch': 1.69}
{'eval_loss': 0.6597477197647095, 'eval_accuracy': 0.6269113149847095, 'eval_runtime': 104.3208, 'eval_samples_per_second': 31.346, 'eval_steps_per_second': 1.965, 'epoch': 2.0}
{'eval_loss': 0.6334237456321716, 'eval_accuracy': 0.6400611620795107, 'eval_runtime': 104.3213, 'eval_samples_per_second': 31.345, 'eval_steps_per_second': 1.965, 'epoch': 3.0}
{'loss': 0.6386, 'learning_rate': 5e-06, 'epoch': 3.39}
{'eval_loss': 0.619999885559082, 'eval_accuracy': 0.6577981651376147, 'eval_runtime': 104.353, 'eval_samples_per_second': 31.336, 'eval_steps_per_second': 1.964, 'epoch': 4.0}
{'eval_loss': 0.6088277101516724, 'eval_accuracy': 0.6810397553516819, 'eval_runtime': 104.4109, 'eval_samples_per_second': 31.319, 'eval_steps_per_second': 1.963, 'epoch': 5.0}
{'loss': 0.5845, 'learning_rate': 7.5e-06, 'epoch': 5.08}
{'eval_loss': 0.6104825139045715, 'eval_accuracy': 0.6853211009174311, 'eval_runtime': 104.4569, 'eval_samples_per_second': 31.305, 'eval_steps_per_second': 1.963, 'epoch': 6.0}
{'loss': 0.4836, 'learning_rate': 1e-05, 'epoch': 6.78}
{'eval_loss': 0.6296809315681458, 'eval_accuracy': 0.7045871559633028, 'eval_runtime': 104.4664, 'eval_samples_per_second': 31.302, 'eval_steps_per_second': 1.962, 'epoch': 7.0}
{'eval_loss': 0.6709818243980408, 'eval_accuracy': 0.708256880733945, 'eval_runtime': 104.3995, 'eval_samples_per_second': 31.322, 'eval_steps_per_second': 1.964, 'epoch': 8.0}
{'loss': 0.3596, 'learning_rate': 1.25e-05, 'epoch': 8.47}
{'eval_loss': 0.7201533317565918, 'eval_accuracy': 0.7085626911314985, 'eval_runtime': 104.4045, 'eval_samples_per_second': 31.32, 'eval_steps_per_second': 1.964, 'epoch': 9.0}
{'eval_loss': 0.79510897397995, 'eval_accuracy': 0.7051987767584098, 'eval_runtime': 104.3524, 'eval_samples_per_second': 31.336, 'eval_steps_per_second': 1.964, 'epoch': 10.0}
{'train_runtime': 8571.5842, 'train_samples_per_second': 10.998, 'train_steps_per_second': 0.344, 'train_loss': 0.5221931974766618, 'epoch': 10.0}
Total training time: 8571.61 seconds
######################################################################
finished
