######################################################################
full model fine-tuning
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 331.58it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
{'eval_loss': 0.7029542922973633, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4009, 'eval_samples_per_second': 29.573, 'eval_steps_per_second': 3.749, 'epoch': 1.0}
{'eval_loss': 0.7021515369415283, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4419, 'eval_samples_per_second': 29.076, 'eval_steps_per_second': 3.686, 'epoch': 2.0}
{'eval_loss': 0.7012475728988647, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4467, 'eval_samples_per_second': 29.019, 'eval_steps_per_second': 3.678, 'epoch': 3.0}
{'eval_loss': 0.7001354098320007, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4556, 'eval_samples_per_second': 28.913, 'eval_steps_per_second': 3.665, 'epoch': 4.0}
{'eval_loss': 0.6984567642211914, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4403, 'eval_samples_per_second': 29.095, 'eval_steps_per_second': 3.688, 'epoch': 5.0}
{'eval_loss': 0.6985869407653809, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4792, 'eval_samples_per_second': 28.639, 'eval_steps_per_second': 3.63, 'epoch': 6.0}
{'eval_loss': 0.6964731812477112, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4565, 'eval_samples_per_second': 28.903, 'eval_steps_per_second': 3.664, 'epoch': 7.0}
{'eval_loss': 0.6955280303955078, 'eval_accuracy': 0.4507042253521127, 'eval_runtime': 2.462, 'eval_samples_per_second': 28.839, 'eval_steps_per_second': 3.656, 'epoch': 8.0}
{'eval_loss': 0.6939992308616638, 'eval_accuracy': 0.4647887323943662, 'eval_runtime': 2.4283, 'eval_samples_per_second': 29.239, 'eval_steps_per_second': 3.706, 'epoch': 9.0}
{'eval_loss': 0.6946085095405579, 'eval_accuracy': 0.4084507042253521, 'eval_runtime': 2.4529, 'eval_samples_per_second': 28.946, 'eval_steps_per_second': 3.669, 'epoch': 10.0}
{'train_runtime': 766.9045, 'train_samples_per_second': 8.28, 'train_steps_per_second': 0.522, 'train_loss': 0.6942733001708984, 'epoch': 10.0}
Total training time: 766.92 seconds
######################################################################
layer-wise fine-tuning top 1
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 444.74it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.2', 'roberta.encoder.layer.3', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6', 'roberta.encoder.layer.7', 'roberta.encoder.layer.8', 'roberta.encoder.layer.9', 'roberta.encoder.layer.10')
{'eval_loss': 0.7030787467956543, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3997, 'eval_samples_per_second': 29.587, 'eval_steps_per_second': 3.75, 'epoch': 1.0}
{'eval_loss': 0.7028352618217468, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4369, 'eval_samples_per_second': 29.136, 'eval_steps_per_second': 3.693, 'epoch': 2.0}
{'eval_loss': 0.7025472521781921, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4386, 'eval_samples_per_second': 29.115, 'eval_steps_per_second': 3.691, 'epoch': 3.0}
{'eval_loss': 0.7021868228912354, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4423, 'eval_samples_per_second': 29.071, 'eval_steps_per_second': 3.685, 'epoch': 4.0}
{'eval_loss': 0.7015400528907776, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4388, 'eval_samples_per_second': 29.113, 'eval_steps_per_second': 3.69, 'epoch': 5.0}
{'eval_loss': 0.7012239098548889, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4418, 'eval_samples_per_second': 29.077, 'eval_steps_per_second': 3.686, 'epoch': 6.0}
{'eval_loss': 0.7004572749137878, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4285, 'eval_samples_per_second': 29.236, 'eval_steps_per_second': 3.706, 'epoch': 7.0}
{'eval_loss': 0.6997836828231812, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.43, 'eval_samples_per_second': 29.219, 'eval_steps_per_second': 3.704, 'epoch': 8.0}
{'eval_loss': 0.6988500356674194, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4306, 'eval_samples_per_second': 29.211, 'eval_steps_per_second': 3.703, 'epoch': 9.0}
{'eval_loss': 0.698087751865387, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.42, 'eval_samples_per_second': 29.339, 'eval_steps_per_second': 3.719, 'epoch': 10.0}
{'train_runtime': 554.4485, 'train_samples_per_second': 11.453, 'train_steps_per_second': 0.721, 'train_loss': 0.6950556182861328, 'epoch': 10.0}
Total training time: 554.46 seconds
######################################################################
layer-wise fine-tuning top 2
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 340.32it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.2', 'roberta.encoder.layer.3', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6', 'roberta.encoder.layer.7', 'roberta.encoder.layer.8', 'roberta.encoder.layer.9')
{'eval_loss': 0.7030787467956543, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.473, 'eval_samples_per_second': 28.711, 'eval_steps_per_second': 3.639, 'epoch': 1.0}
{'eval_loss': 0.7028352618217468, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4177, 'eval_samples_per_second': 29.366, 'eval_steps_per_second': 3.722, 'epoch': 2.0}
{'eval_loss': 0.7025472521781921, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4084, 'eval_samples_per_second': 29.48, 'eval_steps_per_second': 3.737, 'epoch': 3.0}
{'eval_loss': 0.7021868228912354, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4162, 'eval_samples_per_second': 29.385, 'eval_steps_per_second': 3.725, 'epoch': 4.0}
{'eval_loss': 0.7015400528907776, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.5327, 'eval_samples_per_second': 28.033, 'eval_steps_per_second': 3.553, 'epoch': 5.0}
{'eval_loss': 0.7012239098548889, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4757, 'eval_samples_per_second': 28.678, 'eval_steps_per_second': 3.635, 'epoch': 6.0}
{'eval_loss': 0.7004572749137878, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.432, 'eval_samples_per_second': 29.194, 'eval_steps_per_second': 3.701, 'epoch': 7.0}
{'eval_loss': 0.6997836828231812, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4529, 'eval_samples_per_second': 28.946, 'eval_steps_per_second': 3.669, 'epoch': 8.0}
{'eval_loss': 0.6988500356674194, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.432, 'eval_samples_per_second': 29.193, 'eval_steps_per_second': 3.701, 'epoch': 9.0}
{'eval_loss': 0.698087751865387, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4397, 'eval_samples_per_second': 29.102, 'eval_steps_per_second': 3.689, 'epoch': 10.0}
{'train_runtime': 578.3965, 'train_samples_per_second': 10.979, 'train_steps_per_second': 0.692, 'train_loss': 0.6950556182861328, 'epoch': 10.0}
Total training time: 578.42 seconds
######################################################################
layer-wise fine-tuning top 3
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 399.95it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.2', 'roberta.encoder.layer.3', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6', 'roberta.encoder.layer.7', 'roberta.encoder.layer.8')
{'eval_loss': 0.7030749917030334, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4873, 'eval_samples_per_second': 28.545, 'eval_steps_per_second': 3.618, 'epoch': 1.0}
{'eval_loss': 0.7027871012687683, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4494, 'eval_samples_per_second': 28.987, 'eval_steps_per_second': 3.674, 'epoch': 2.0}
{'eval_loss': 0.7024653553962708, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4556, 'eval_samples_per_second': 28.913, 'eval_steps_per_second': 3.665, 'epoch': 3.0}
{'eval_loss': 0.7020515203475952, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.44, 'eval_samples_per_second': 29.098, 'eval_steps_per_second': 3.688, 'epoch': 4.0}
{'eval_loss': 0.7013034224510193, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4474, 'eval_samples_per_second': 29.011, 'eval_steps_per_second': 3.677, 'epoch': 5.0}
{'eval_loss': 0.701036274433136, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4324, 'eval_samples_per_second': 29.189, 'eval_steps_per_second': 3.7, 'epoch': 6.0}
{'eval_loss': 0.7001524567604065, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4383, 'eval_samples_per_second': 29.119, 'eval_steps_per_second': 3.691, 'epoch': 7.0}
{'eval_loss': 0.699428915977478, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4503, 'eval_samples_per_second': 28.976, 'eval_steps_per_second': 3.673, 'epoch': 8.0}
{'eval_loss': 0.6984150409698486, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4422, 'eval_samples_per_second': 29.072, 'eval_steps_per_second': 3.685, 'epoch': 9.0}
{'eval_loss': 0.6977096199989319, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.444, 'eval_samples_per_second': 29.05, 'eval_steps_per_second': 3.682, 'epoch': 10.0}
{'train_runtime': 584.4025, 'train_samples_per_second': 10.866, 'train_steps_per_second': 0.684, 'train_loss': 0.6949848937988281, 'epoch': 10.0}
Total training time: 584.44 seconds
######################################################################
layer-wise fine-tuning top 4
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 405.51it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.2', 'roberta.encoder.layer.3', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6', 'roberta.encoder.layer.7')
{'eval_loss': 0.7030708193778992, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4614, 'eval_samples_per_second': 28.845, 'eval_steps_per_second': 3.656, 'epoch': 1.0}
{'eval_loss': 0.7027527093887329, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4366, 'eval_samples_per_second': 29.139, 'eval_steps_per_second': 3.694, 'epoch': 2.0}
{'eval_loss': 0.7024022936820984, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4315, 'eval_samples_per_second': 29.201, 'eval_steps_per_second': 3.701, 'epoch': 3.0}
{'eval_loss': 0.7019415497779846, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4368, 'eval_samples_per_second': 29.136, 'eval_steps_per_second': 3.693, 'epoch': 4.0}
{'eval_loss': 0.7011319398880005, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4226, 'eval_samples_per_second': 29.307, 'eval_steps_per_second': 3.715, 'epoch': 5.0}
{'eval_loss': 0.7009010314941406, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.424, 'eval_samples_per_second': 29.291, 'eval_steps_per_second': 3.713, 'epoch': 6.0}
{'eval_loss': 0.6999350786209106, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4216, 'eval_samples_per_second': 29.32, 'eval_steps_per_second': 3.717, 'epoch': 7.0}
{'eval_loss': 0.6991898417472839, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4369, 'eval_samples_per_second': 29.135, 'eval_steps_per_second': 3.693, 'epoch': 8.0}
{'eval_loss': 0.6981378197669983, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4226, 'eval_samples_per_second': 29.307, 'eval_steps_per_second': 3.715, 'epoch': 9.0}
{'eval_loss': 0.6974589228630066, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4318, 'eval_samples_per_second': 29.197, 'eval_steps_per_second': 3.701, 'epoch': 10.0}
{'train_runtime': 592.2761, 'train_samples_per_second': 10.721, 'train_steps_per_second': 0.675, 'train_loss': 0.6949294281005859, 'epoch': 10.0}
Total training time: 592.30 seconds
######################################################################
layer-wise fine-tuning top 5
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 313.11it/s]
/home/schalkapurka_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.2', 'roberta.encoder.layer.3', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6')
{'eval_loss': 0.7030672430992126, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.3565, 'eval_samples_per_second': 30.129, 'eval_steps_per_second': 3.819, 'epoch': 1.0}
{'eval_loss': 0.7027284502983093, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4339, 'eval_samples_per_second': 29.171, 'eval_steps_per_second': 3.698, 'epoch': 2.0}
{'eval_loss': 0.7023521065711975, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4498, 'eval_samples_per_second': 28.981, 'eval_steps_per_second': 3.674, 'epoch': 3.0}
{'eval_loss': 0.7018471360206604, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.5096, 'eval_samples_per_second': 28.291, 'eval_steps_per_second': 3.586, 'epoch': 4.0}
{'eval_loss': 0.7009871602058411, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4513, 'eval_samples_per_second': 28.964, 'eval_steps_per_second': 3.672, 'epoch': 5.0}
{'eval_loss': 0.7007901668548584, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.447, 'eval_samples_per_second': 29.015, 'eval_steps_per_second': 3.678, 'epoch': 6.0}
{'eval_loss': 0.6997619271278381, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4453, 'eval_samples_per_second': 29.035, 'eval_steps_per_second': 3.68, 'epoch': 7.0}
{'eval_loss': 0.6990103721618652, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4483, 'eval_samples_per_second': 28.999, 'eval_steps_per_second': 3.676, 'epoch': 8.0}
{'eval_loss': 0.6979289650917053, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4622, 'eval_samples_per_second': 28.836, 'eval_steps_per_second': 3.655, 'epoch': 9.0}
{'eval_loss': 0.6972774267196655, 'eval_accuracy': 0.43661971830985913, 'eval_runtime': 2.4623, 'eval_samples_per_second': 28.835, 'eval_steps_per_second': 3.655, 'epoch': 10.0}
{'train_runtime': 635.3063, 'train_samples_per_second': 9.995, 'train_steps_per_second': 0.63, 'train_loss': 0.69488525390625, 'epoch': 10.0}
Total training time: 635.33 seconds
######################################################################
finished
