######################################################################
layer-wise fine-tuning top 1
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 378.05it/s]
Map:   0%|          | 0/250 [00:00<?, ? examples/s]Map: 100%|██████████| 250/250 [00:00<00:00, 1928.43 examples/s]                                                               Map:   0%|          | 0/56 [00:00<?, ? examples/s]                                                  /home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.2', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6', 'roberta.encoder.layer.7', 'roberta.encoder.layer.8', 'roberta.encoder.layer.9', 'roberta.encoder.layer.10', 'roberta.encoder.layer.11')
{'eval_loss': 1.1085377931594849, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.5558, 'eval_samples_per_second': 35.994, 'eval_steps_per_second': 2.571, 'epoch': 1.0}
{'eval_loss': 1.1084378957748413, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.5644, 'eval_samples_per_second': 35.798, 'eval_steps_per_second': 2.557, 'epoch': 2.0}
{'eval_loss': 1.1082741022109985, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.5769, 'eval_samples_per_second': 35.512, 'eval_steps_per_second': 2.537, 'epoch': 3.0}
{'eval_loss': 1.1080445051193237, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.5763, 'eval_samples_per_second': 35.526, 'eval_steps_per_second': 2.538, 'epoch': 4.0}
{'eval_loss': 1.1077467203140259, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7964, 'eval_samples_per_second': 31.173, 'eval_steps_per_second': 2.227, 'epoch': 5.0}
{'eval_loss': 1.1073857545852661, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7865, 'eval_samples_per_second': 31.345, 'eval_steps_per_second': 2.239, 'epoch': 6.0}
{'eval_loss': 1.1069709062576294, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7853, 'eval_samples_per_second': 31.367, 'eval_steps_per_second': 2.241, 'epoch': 7.0}
{'eval_loss': 1.1064907312393188, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.788, 'eval_samples_per_second': 31.32, 'eval_steps_per_second': 2.237, 'epoch': 8.0}
{'eval_loss': 1.10593581199646, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7915, 'eval_samples_per_second': 31.259, 'eval_steps_per_second': 2.233, 'epoch': 9.0}
{'eval_loss': 1.1053102016448975, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7881, 'eval_samples_per_second': 31.319, 'eval_steps_per_second': 2.237, 'epoch': 10.0}
{'train_runtime': 275.223, 'train_samples_per_second': 9.084, 'train_steps_per_second': 0.291, 'train_loss': 1.1172542572021484, 'epoch': 10.0}
Total training time: 275.23 seconds
######################################################################
layer-wise fine-tuning top 2
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 380.42it/s]
Map:   0%|          | 0/56 [00:00<?, ? examples/s]                                                  /home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.2', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6', 'roberta.encoder.layer.7', 'roberta.encoder.layer.8', 'roberta.encoder.layer.10', 'roberta.encoder.layer.11')
{'eval_loss': 1.1085293292999268, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.5943, 'eval_samples_per_second': 35.124, 'eval_steps_per_second': 2.509, 'epoch': 1.0}
{'eval_loss': 1.1084015369415283, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.8012, 'eval_samples_per_second': 31.091, 'eval_steps_per_second': 2.221, 'epoch': 2.0}
{'eval_loss': 1.108192801475525, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.8029, 'eval_samples_per_second': 31.061, 'eval_steps_per_second': 2.219, 'epoch': 3.0}
{'eval_loss': 1.1079000234603882, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.802, 'eval_samples_per_second': 31.077, 'eval_steps_per_second': 2.22, 'epoch': 4.0}
{'eval_loss': 1.1075211763381958, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.8057, 'eval_samples_per_second': 31.013, 'eval_steps_per_second': 2.215, 'epoch': 5.0}
{'eval_loss': 1.1070605516433716, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7889, 'eval_samples_per_second': 31.305, 'eval_steps_per_second': 2.236, 'epoch': 6.0}
{'eval_loss': 1.1065316200256348, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7926, 'eval_samples_per_second': 31.24, 'eval_steps_per_second': 2.231, 'epoch': 7.0}
{'eval_loss': 1.105921983718872, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7908, 'eval_samples_per_second': 31.27, 'eval_steps_per_second': 2.234, 'epoch': 8.0}
{'eval_loss': 1.1052180528640747, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.6346, 'eval_samples_per_second': 34.26, 'eval_steps_per_second': 2.447, 'epoch': 9.0}
{'eval_loss': 1.10442316532135, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7935, 'eval_samples_per_second': 31.223, 'eval_steps_per_second': 2.23, 'epoch': 10.0}
{'train_runtime': 296.5713, 'train_samples_per_second': 8.43, 'train_steps_per_second': 0.27, 'train_loss': 1.1167921066284179, 'epoch': 10.0}
Total training time: 296.59 seconds
######################################################################
layer-wise fine-tuning top 3
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 475.74it/s]
/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.2', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6', 'roberta.encoder.layer.7', 'roberta.encoder.layer.10', 'roberta.encoder.layer.11')
{'eval_loss': 1.1085236072540283, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.5974, 'eval_samples_per_second': 35.057, 'eval_steps_per_second': 2.504, 'epoch': 1.0}
{'eval_loss': 1.10837721824646, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7936, 'eval_samples_per_second': 31.222, 'eval_steps_per_second': 2.23, 'epoch': 2.0}
{'eval_loss': 1.1081377267837524, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.794, 'eval_samples_per_second': 31.216, 'eval_steps_per_second': 2.23, 'epoch': 3.0}
{'eval_loss': 1.107802391052246, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7896, 'eval_samples_per_second': 31.291, 'eval_steps_per_second': 2.235, 'epoch': 4.0}
{'eval_loss': 1.1073696613311768, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.6975, 'eval_samples_per_second': 32.99, 'eval_steps_per_second': 2.356, 'epoch': 5.0}
{'eval_loss': 1.1068426370620728, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7951, 'eval_samples_per_second': 31.196, 'eval_steps_per_second': 2.228, 'epoch': 6.0}
{'eval_loss': 1.1062390804290771, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.792, 'eval_samples_per_second': 31.251, 'eval_steps_per_second': 2.232, 'epoch': 7.0}
{'eval_loss': 1.105542778968811, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.8019, 'eval_samples_per_second': 31.078, 'eval_steps_per_second': 2.22, 'epoch': 8.0}
{'eval_loss': 1.104738473892212, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.8007, 'eval_samples_per_second': 31.1, 'eval_steps_per_second': 2.221, 'epoch': 9.0}
{'eval_loss': 1.103829264640808, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7911, 'eval_samples_per_second': 31.266, 'eval_steps_per_second': 2.233, 'epoch': 10.0}
{'train_runtime': 303.8065, 'train_samples_per_second': 8.229, 'train_steps_per_second': 0.263, 'train_loss': 1.11649169921875, 'epoch': 10.0}
Total training time: 303.82 seconds
######################################################################
layer-wise fine-tuning top 4
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 380.64it/s]
/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6', 'roberta.encoder.layer.7', 'roberta.encoder.layer.10', 'roberta.encoder.layer.11')
{'eval_loss': 1.1085224151611328, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.5991, 'eval_samples_per_second': 35.02, 'eval_steps_per_second': 2.501, 'epoch': 1.0}
{'eval_loss': 1.1083723306655884, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.8034, 'eval_samples_per_second': 31.053, 'eval_steps_per_second': 2.218, 'epoch': 2.0}
{'eval_loss': 1.1081278324127197, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.8396, 'eval_samples_per_second': 30.441, 'eval_steps_per_second': 2.174, 'epoch': 3.0}
{'eval_loss': 1.107786774635315, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.8016, 'eval_samples_per_second': 31.084, 'eval_steps_per_second': 2.22, 'epoch': 4.0}
{'eval_loss': 1.1073455810546875, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.798, 'eval_samples_per_second': 31.147, 'eval_steps_per_second': 2.225, 'epoch': 5.0}
{'eval_loss': 1.1068081855773926, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7934, 'eval_samples_per_second': 31.226, 'eval_steps_per_second': 2.23, 'epoch': 6.0}
{'eval_loss': 1.1061867475509644, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7932, 'eval_samples_per_second': 31.229, 'eval_steps_per_second': 2.231, 'epoch': 7.0}
{'eval_loss': 1.105466604232788, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7985, 'eval_samples_per_second': 31.137, 'eval_steps_per_second': 2.224, 'epoch': 8.0}
{'eval_loss': 1.104638934135437, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7906, 'eval_samples_per_second': 31.274, 'eval_steps_per_second': 2.234, 'epoch': 9.0}
{'eval_loss': 1.103708267211914, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7935, 'eval_samples_per_second': 31.225, 'eval_steps_per_second': 2.23, 'epoch': 10.0}
{'train_runtime': 310.6352, 'train_samples_per_second': 8.048, 'train_steps_per_second': 0.258, 'train_loss': 1.1164384841918946, 'epoch': 10.0}
Total training time: 310.65 seconds
######################################################################
layer-wise fine-tuning top 5
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 439.44it/s]
/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('roberta.encoder.layer.0', 'roberta.encoder.layer.1', 'roberta.encoder.layer.4', 'roberta.encoder.layer.5', 'roberta.encoder.layer.6', 'roberta.encoder.layer.7', 'roberta.encoder.layer.11')
{'eval_loss': 1.1085224151611328, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.5872, 'eval_samples_per_second': 35.282, 'eval_steps_per_second': 2.52, 'epoch': 1.0}
{'eval_loss': 1.1083723306655884, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7938, 'eval_samples_per_second': 31.218, 'eval_steps_per_second': 2.23, 'epoch': 2.0}
{'eval_loss': 1.1081278324127197, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7595, 'eval_samples_per_second': 31.827, 'eval_steps_per_second': 2.273, 'epoch': 3.0}
{'eval_loss': 1.107786774635315, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7836, 'eval_samples_per_second': 31.398, 'eval_steps_per_second': 2.243, 'epoch': 4.0}
{'eval_loss': 1.1073455810546875, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7894, 'eval_samples_per_second': 31.296, 'eval_steps_per_second': 2.235, 'epoch': 5.0}
{'eval_loss': 1.1068081855773926, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7979, 'eval_samples_per_second': 31.148, 'eval_steps_per_second': 2.225, 'epoch': 6.0}
{'eval_loss': 1.1061867475509644, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.598, 'eval_samples_per_second': 35.045, 'eval_steps_per_second': 2.503, 'epoch': 7.0}
{'eval_loss': 1.105466604232788, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7922, 'eval_samples_per_second': 31.246, 'eval_steps_per_second': 2.232, 'epoch': 8.0}
{'eval_loss': 1.104638934135437, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7904, 'eval_samples_per_second': 31.278, 'eval_steps_per_second': 2.234, 'epoch': 9.0}
{'eval_loss': 1.103708267211914, 'eval_accuracy': 0.08928571428571429, 'eval_runtime': 1.7872, 'eval_samples_per_second': 31.334, 'eval_steps_per_second': 2.238, 'epoch': 10.0}
{'train_runtime': 323.7845, 'train_samples_per_second': 7.721, 'train_steps_per_second': 0.247, 'train_loss': 1.1164384841918946, 'epoch': 10.0}
Total training time: 323.80 seconds
######################################################################
finished
