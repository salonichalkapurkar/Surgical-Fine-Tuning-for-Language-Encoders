######################################################################
layer-wise fine-tuning top 2
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 443.31it/s]
/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.1', 'bert.encoder.layer.2', 'bert.encoder.layer.3', 'bert.encoder.layer.4', 'bert.encoder.layer.6', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
{'eval_loss': 0.8313108086585999, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.8928, 'eval_samples_per_second': 31.149, 'eval_steps_per_second': 2.024, 'epoch': 1.0}
{'eval_loss': 0.8058705925941467, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.9096, 'eval_samples_per_second': 31.09, 'eval_steps_per_second': 2.02, 'epoch': 2.0}
{'eval_loss': 0.7648831009864807, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.8973, 'eval_samples_per_second': 31.133, 'eval_steps_per_second': 2.023, 'epoch': 3.0}
{'eval_loss': 0.7179539799690247, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.863, 'eval_samples_per_second': 31.254, 'eval_steps_per_second': 2.031, 'epoch': 4.0}
{'eval_loss': 0.6974347233772278, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.8998, 'eval_samples_per_second': 31.124, 'eval_steps_per_second': 2.023, 'epoch': 5.0}
{'eval_loss': 0.6929090023040771, 'eval_accuracy': 0.5415162454873647, 'eval_runtime': 8.8917, 'eval_samples_per_second': 31.153, 'eval_steps_per_second': 2.024, 'epoch': 6.0}
{'loss': 0.7827, 'learning_rate': 2.5e-06, 'epoch': 6.41}
{'eval_loss': 0.6877739429473877, 'eval_accuracy': 0.5415162454873647, 'eval_runtime': 8.8767, 'eval_samples_per_second': 31.205, 'eval_steps_per_second': 2.028, 'epoch': 7.0}
{'eval_loss': 0.6830514669418335, 'eval_accuracy': 0.5703971119133574, 'eval_runtime': 8.8788, 'eval_samples_per_second': 31.198, 'eval_steps_per_second': 2.027, 'epoch': 8.0}
{'eval_loss': 0.6802492737770081, 'eval_accuracy': 0.5667870036101083, 'eval_runtime': 8.8841, 'eval_samples_per_second': 31.179, 'eval_steps_per_second': 2.026, 'epoch': 9.0}
{'eval_loss': 0.6770821809768677, 'eval_accuracy': 0.5631768953068592, 'eval_runtime': 8.9315, 'eval_samples_per_second': 31.014, 'eval_steps_per_second': 2.015, 'epoch': 10.0}
{'train_runtime': 1954.691, 'train_samples_per_second': 12.739, 'train_steps_per_second': 0.399, 'train_loss': 0.7416505080003005, 'epoch': 10.0}
Total training time: 1954.70 seconds
######################################################################
layer-wise fine-tuning top 3
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 568.82it/s]
/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.1', 'bert.encoder.layer.3', 'bert.encoder.layer.4', 'bert.encoder.layer.6', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
{'eval_loss': 0.8311659097671509, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.9227, 'eval_samples_per_second': 31.044, 'eval_steps_per_second': 2.017, 'epoch': 1.0}
{'eval_loss': 0.8051093220710754, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.9155, 'eval_samples_per_second': 31.069, 'eval_steps_per_second': 2.019, 'epoch': 2.0}
{'eval_loss': 0.7624504566192627, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.8788, 'eval_samples_per_second': 31.198, 'eval_steps_per_second': 2.027, 'epoch': 3.0}
{'eval_loss': 0.715483546257019, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.883, 'eval_samples_per_second': 31.183, 'eval_steps_per_second': 2.026, 'epoch': 4.0}
{'eval_loss': 0.6966676115989685, 'eval_accuracy': 0.516245487364621, 'eval_runtime': 8.8385, 'eval_samples_per_second': 31.34, 'eval_steps_per_second': 2.037, 'epoch': 5.0}
{'eval_loss': 0.6915610432624817, 'eval_accuracy': 0.5415162454873647, 'eval_runtime': 8.9069, 'eval_samples_per_second': 31.099, 'eval_steps_per_second': 2.021, 'epoch': 6.0}
{'loss': 0.7805, 'learning_rate': 2.5e-06, 'epoch': 6.41}
{'eval_loss': 0.6866273283958435, 'eval_accuracy': 0.5487364620938628, 'eval_runtime': 8.897, 'eval_samples_per_second': 31.134, 'eval_steps_per_second': 2.023, 'epoch': 7.0}
{'eval_loss': 0.6821452975273132, 'eval_accuracy': 0.5703971119133574, 'eval_runtime': 8.8436, 'eval_samples_per_second': 31.322, 'eval_steps_per_second': 2.035, 'epoch': 8.0}
{'eval_loss': 0.6791930794715881, 'eval_accuracy': 0.5667870036101083, 'eval_runtime': 8.9025, 'eval_samples_per_second': 31.115, 'eval_steps_per_second': 2.022, 'epoch': 9.0}
{'eval_loss': 0.6761817336082458, 'eval_accuracy': 0.5776173285198556, 'eval_runtime': 8.8619, 'eval_samples_per_second': 31.257, 'eval_steps_per_second': 2.031, 'epoch': 10.0}
{'train_runtime': 2004.3758, 'train_samples_per_second': 12.423, 'train_steps_per_second': 0.389, 'train_loss': 0.7372747567983774, 'epoch': 10.0}
Total training time: 2004.39 seconds
######################################################################
layer-wise fine-tuning top 4
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 470.95it/s]
/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.1', 'bert.encoder.layer.3', 'bert.encoder.layer.4', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
{'eval_loss': 0.8307209610939026, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.8789, 'eval_samples_per_second': 31.197, 'eval_steps_per_second': 2.027, 'epoch': 1.0}
{'eval_loss': 0.802330493927002, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.8741, 'eval_samples_per_second': 31.214, 'eval_steps_per_second': 2.028, 'epoch': 2.0}
{'eval_loss': 0.7514840364456177, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.8542, 'eval_samples_per_second': 31.285, 'eval_steps_per_second': 2.033, 'epoch': 3.0}
{'eval_loss': 0.6995183229446411, 'eval_accuracy': 0.51985559566787, 'eval_runtime': 8.8846, 'eval_samples_per_second': 31.177, 'eval_steps_per_second': 2.026, 'epoch': 4.0}
{'eval_loss': 0.6919184923171997, 'eval_accuracy': 0.5054151624548736, 'eval_runtime': 8.825, 'eval_samples_per_second': 31.388, 'eval_steps_per_second': 2.04, 'epoch': 5.0}
{'eval_loss': 0.6846269369125366, 'eval_accuracy': 0.5451263537906137, 'eval_runtime': 8.8882, 'eval_samples_per_second': 31.165, 'eval_steps_per_second': 2.025, 'epoch': 6.0}
{'loss': 0.7733, 'learning_rate': 2.5e-06, 'epoch': 6.41}
{'eval_loss': 0.6775118112564087, 'eval_accuracy': 0.5631768953068592, 'eval_runtime': 9.0517, 'eval_samples_per_second': 30.602, 'eval_steps_per_second': 1.989, 'epoch': 7.0}
{'eval_loss': 0.6716152429580688, 'eval_accuracy': 0.5703971119133574, 'eval_runtime': 8.8871, 'eval_samples_per_second': 31.169, 'eval_steps_per_second': 2.025, 'epoch': 8.0}
{'eval_loss': 0.6654738187789917, 'eval_accuracy': 0.5776173285198556, 'eval_runtime': 8.9193, 'eval_samples_per_second': 31.056, 'eval_steps_per_second': 2.018, 'epoch': 9.0}
{'eval_loss': 0.659336268901825, 'eval_accuracy': 0.6064981949458483, 'eval_runtime': 8.8958, 'eval_samples_per_second': 31.138, 'eval_steps_per_second': 2.023, 'epoch': 10.0}
{'train_runtime': 2056.414, 'train_samples_per_second': 12.108, 'train_steps_per_second': 0.379, 'train_loss': 0.7278378608899239, 'epoch': 10.0}
Total training time: 2056.43 seconds
######################################################################
layer-wise fine-tuning top 5
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Using cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 390.94it/s]
/home/gbelapurkar_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
layers to freeze ('bert.encoder.layer.0', 'bert.encoder.layer.3', 'bert.encoder.layer.4', 'bert.encoder.layer.8', 'bert.encoder.layer.9', 'bert.encoder.layer.10', 'bert.encoder.layer.11')
{'eval_loss': 0.8306233882904053, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.9232, 'eval_samples_per_second': 31.043, 'eval_steps_per_second': 2.017, 'epoch': 1.0}
{'eval_loss': 0.8016884326934814, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.9204, 'eval_samples_per_second': 31.052, 'eval_steps_per_second': 2.018, 'epoch': 2.0}
{'eval_loss': 0.7491555213928223, 'eval_accuracy': 0.5270758122743683, 'eval_runtime': 8.9032, 'eval_samples_per_second': 31.112, 'eval_steps_per_second': 2.022, 'epoch': 3.0}
{'eval_loss': 0.6976664662361145, 'eval_accuracy': 0.516245487364621, 'eval_runtime': 9.1243, 'eval_samples_per_second': 30.358, 'eval_steps_per_second': 1.973, 'epoch': 4.0}
{'eval_loss': 0.6907312273979187, 'eval_accuracy': 0.516245487364621, 'eval_runtime': 8.9303, 'eval_samples_per_second': 31.018, 'eval_steps_per_second': 2.016, 'epoch': 5.0}
{'eval_loss': 0.6833319067955017, 'eval_accuracy': 0.5523465703971119, 'eval_runtime': 8.9111, 'eval_samples_per_second': 31.085, 'eval_steps_per_second': 2.02, 'epoch': 6.0}
{'loss': 0.7718, 'learning_rate': 2.5e-06, 'epoch': 6.41}
{'eval_loss': 0.6765326261520386, 'eval_accuracy': 0.5703971119133574, 'eval_runtime': 8.9313, 'eval_samples_per_second': 31.014, 'eval_steps_per_second': 2.015, 'epoch': 7.0}
{'eval_loss': 0.6715182065963745, 'eval_accuracy': 0.5703971119133574, 'eval_runtime': 8.9135, 'eval_samples_per_second': 31.076, 'eval_steps_per_second': 2.019, 'epoch': 8.0}
{'eval_loss': 0.6642333269119263, 'eval_accuracy': 0.5848375451263538, 'eval_runtime': 8.9046, 'eval_samples_per_second': 31.108, 'eval_steps_per_second': 2.021, 'epoch': 9.0}
{'eval_loss': 0.6593698859214783, 'eval_accuracy': 0.5956678700361011, 'eval_runtime': 8.8977, 'eval_samples_per_second': 31.132, 'eval_steps_per_second': 2.023, 'epoch': 10.0}
{'train_runtime': 2138.4627, 'train_samples_per_second': 11.644, 'train_steps_per_second': 0.365, 'train_loss': 0.7245216565254408, 'epoch': 10.0}
Total training time: 2138.49 seconds
######################################################################
finished
